# üöÑ SHINKANSEN COMMERCE - COMPREHENSIVE PROJECT PLAN

**Version**: 2.0 (Compressed & Refined)
**Target Duration**: 20-24 weeks
**Focus**: Core E-commerce + System Architecture
**Cloud**: AWS-first, cloud-agnostic design
**Approach**: Breadth-first MVP

---

## üìã EXECUTIVE SUMMARY

**Objective**: Build a production-grade, Japan-focused e-commerce platform demonstrating senior backend engineering skills suitable for Japanese tech companies (Rakuten, PayPay, Mercari).

**Key Priorities**:
1. ‚úÖ Core E-commerce (Products, Orders, Payments, Users)
2. ‚úÖ System Architecture (Microservices, Monorepo, Kubernetes)
3. ‚úÖ Japan-Specific Features (Konbini payments, Point systems)
4. ‚úÖ Cloud-Native (AWS-first, but portable)
5. ‚úÖ Production-Ready (CI/CD, Monitoring, Observability)

**Timeline**: 20-24 weeks (accelerated from 34 weeks)
**Philosophy**: Spec-first development - Protobuf definitions are source of truth

---

## üéØ SUCCESS CRITERIA

### Technical Excellence (Architecture Focus)
- ‚úÖ Well-defined service boundaries (DDD approach)
- ‚úÖ Clear separation of concerns (Gateway, Services, Infrastructure)
- ‚úÖ Type-safe communication (gRPC, Protocol Buffers)
- ‚úÖ Scalable architecture (Horizontal scaling, caching, read replicas)
- ‚úÖ Observability (Metrics, Logging, Tracing)
- ‚úÖ Resilience (Circuit breakers, retries, timeouts)

### Business Features (Core E-commerce MVP)
- ‚úÖ Product browsing and search
- ‚úÖ Shopping cart (session + persistent)
- ‚úÖ Order placement and management
- ‚úÖ User authentication and profiles
- ‚úÖ Multiple payment methods (Credit card, Konbini)
- ‚úÖ Point system (basic)
- ‚úÖ Basic inventory management

### Portfolio Value (For Japanese Employers)
- ‚úÖ Demonstrates understanding of distributed systems
- ‚úÖ Shows experience with microservices architecture
- ‚úÖ Proves ability to design scalable systems
- ‚úÖ Exhibits Japan-specific e-commerce knowledge
- ‚úÖ Shows DevOps expertise (Kubernetes, CI/CD, AWS)
- ‚úÖ Demonstrates polyglot capabilities (Go, Rust, Python)

---

## üó∫ OVERALL TIMELINE (20-24 Weeks)

```
Week 1-4:   Phase 1: Foundation ‚úÖ COMPLETED
Week 5-8:   Phase 2: Core Services (MVP)
Week 9-12:  Phase 3: Payment & Points (Japan-Specific)
Week 13-16: Phase 4: Delivery & Inventory
Week 17-20: Phase 5: Infrastructure & DevOps
Week 21-24: Phase 6: Polish, Testing, Documentation
```

---

## PHASE 1: FOUNDATION ‚úÖ COMPLETED
**Duration**: Week 1-4
**Status**: ‚úÖ Complete
**Focus**: Architecture setup, monorepo structure, basic infrastructure

### Completed Deliverables
- ‚úÖ Monorepo structure with Go workspaces
- ‚úÖ Complete protobuf definitions (18 files)
- ‚úÖ API Gateway implementation (Go)
- ‚úÖ Product Service skeleton (Go)
- ‚úÖ Docker Compose infrastructure
- ‚úÖ Kubernetes manifests (base layer)
- ‚úÖ CI/CD pipeline (GitHub Actions)
- ‚úÖ Comprehensive documentation

### Architecture Demonstrated
- ‚úÖ Monorepo design (polyglot workspace)
- ‚úÖ API Gateway pattern (gRPC to REST translation)
- ‚úÖ Microservices architecture (service boundaries)
- ‚úÖ Infrastructure as Code (Docker Compose, Kubernetes)
- ‚úÖ CI/CD automation (GitHub Actions)
- ‚úÖ Observability stack (Prometheus, Grafana, Jaeger)

**See**: `docs/PHASE1_IMPLEMENTATION_SUMMARY.md`

---

## PHASE 2: CORE SERVICES (MVP)
**Duration**: Week 5-8 (4 weeks)
**Priority**: üî• CRITICAL
**Focus**: Core e-commerce functionality

### Week 5: Complete Product Service

#### Architecture Focus
```
API Gateway ‚Üí Product Service ‚Üí [Redis Cache] ‚Üí PostgreSQL
                                    ‚Üì
                             (Cache Miss)
                                    ‚Üì
                             PostgreSQL
```

#### Tasks

**1. Database Schema** (`services/product-service/migrations/`)
```sql
-- 001_create_products.sql
CREATE TABLE products (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    description TEXT,
    category_id UUID REFERENCES categories(id),
    sku VARCHAR(100) UNIQUE NOT NULL,
    price_units BIGINT NOT NULL,
    price_currency VARCHAR(3) NOT NULL DEFAULT 'JPY',
    active BOOLEAN DEFAULT true,
    stock_quantity INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Indexes for performance
CREATE INDEX idx_products_category ON products(category_id);
CREATE INDEX idx_products_sku ON products(sku);
CREATE INDEX idx_products_active ON products(active);
CREATE INDEX idx_products_created ON products(created_at DESC);

-- Full-text search
CREATE INDEX idx_products_search ON products USING gin(
    to_tsvector('english', name || ' ' || COALESCE(description, ''))
);

-- 002_create_categories.sql
CREATE TABLE categories (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    parent_id UUID REFERENCES categories(id),
    level INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_categories_parent ON categories(parent_id);

-- 003_create_product_variants.sql
CREATE TABLE product_variants (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    product_id UUID REFERENCES products(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,
    attributes JSONB,
    price_units BIGINT NOT NULL,
    price_currency VARCHAR(3) NOT NULL DEFAULT 'JPY',
    sku VARCHAR(100) UNIQUE,
    stock_quantity INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_variants_product ON product_variants(product_id);
```

**2. SQL Queries** (`services/product-service/queries/`)
- `get_product.sql`
- `list_products.sql`
- `create_product.sql`
- `update_product.sql`
- `delete_product.sql`
- `search_products.sql`
- `get_product_variants.sql`

**3. Repository Layer**
- Run `make sqlc-gen` to generate Go code
- Review generated `internal/db/*.go`
- Add custom queries if needed

**4. Service Layer with Caching**
```go
// Cache strategy: Write-through
// TTL: 5 minutes for products, 1 hour for categories

func (s *ProductService) GetProduct(ctx context.Context, req *pb.GetProductRequest) (*pb.GetProductResponse, error) {
    // 1. Try Redis cache
    cached, err := s.cache.Get(ctx, "product:"+req.ProductId)
    if err == nil {
        return cached, nil
    }

    // 2. Cache miss - query database
    product, err := s.queries.GetProduct(ctx, req.ProductId)
    if err != nil {
        return nil, err
    }

    // 3. Write to cache
    s.cache.Set(ctx, "product:"+req.ProductId, product, 5*time.Minute)

    return product, nil
}
```

**5. Testing**
```bash
# Unit tests
make test

# Integration tests with testcontainers
make test-integration

# Load testing (10K concurrent reads)
k6 run tests/load/product_load.js
```

**6. API Gateway Integration**
- Register Product Service handlers in `internal/handler/register.go`
- Add gRPC client configuration
- Test end-to-end: Gateway ‚Üí Product Service ‚Üí DB

#### Deliverables
- ‚úÖ Fully functional Product Service
- ‚úÖ Redis caching layer (multi-level)
- ‚úÖ 80%+ test coverage
- ‚úÖ Load tested (10K concurrent reads)
- ‚úÖ Integrated with API Gateway

#### Architecture Highlights
- **Caching Pattern**: Cache-aside with TTL
- **Query Optimization**: Full-text search, composite indexes
- **Scalability**: Read-through caching, connection pooling
- **Observability**: Metrics for cache hit rate, query duration

---

### Week 6: Order Service

#### Architecture Focus
```
User ‚Üí API Gateway ‚Üí Order Service
                      ‚îú‚Üí [Redis] Shopping Cart
                      ‚îú‚Üí Product Service (gRPC)
                      ‚îú‚Üí Inventory Service (gRPC)
                      ‚îî‚Üí Kafka (Events)
```

#### Tasks

**1. Database Schema**
```sql
-- 001_create_carts.sql
CREATE TABLE carts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID,
    session_id VARCHAR(255),
    expires_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_carts_user ON carts(user_id);
CREATE INDEX idx_carts_session ON carts(session_id);
CREATE INDEX idx_carts_expires ON carts(expires_at);

-- 002_create_cart_items.sql
CREATE TABLE cart_items (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    cart_id UUID REFERENCES carts(id) ON DELETE CASCADE,
    product_id UUID NOT NULL,
    variant_id UUID,
    quantity INT NOT NULL CHECK (quantity > 0),
    unit_price_units BIGINT NOT NULL,
    added_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_cart_items_cart ON cart_items(cart_id);

-- 003_create_orders.sql
CREATE TABLE orders (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    order_number VARCHAR(20) UNIQUE NOT NULL,
    user_id UUID,
    status VARCHAR(50) NOT NULL DEFAULT 'PENDING',
    subtotal_amount BIGINT NOT NULL,
    tax_amount BIGINT NOT NULL,
    discount_amount BIGINT DEFAULT 0,
    total_amount BIGINT NOT NULL,
    currency VARCHAR(3) NOT NULL DEFAULT 'JPY',
    shipping_name VARCHAR(255) NOT NULL,
    shipping_phone VARCHAR(20) NOT NULL,
    shipping_postal_code VARCHAR(10) NOT NULL,
    shipping_prefecture VARCHAR(100) NOT NULL,
    shipping_city VARCHAR(100) NOT NULL,
    shipping_address_line1 VARCHAR(255) NOT NULL,
    shipping_address_line2 VARCHAR(255),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    deleted_at TIMESTAMP
);

CREATE INDEX idx_orders_user ON orders(user_id);
CREATE INDEX idx_orders_status ON orders(status);
CREATE INDEX idx_orders_number ON orders(order_number);
CREATE INDEX idx_orders_created ON orders(created_at DESC);

-- 004_create_order_items.sql
CREATE TABLE order_items (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    order_id UUID REFERENCES orders(id) ON DELETE CASCADE,
    product_id UUID NOT NULL,
    variant_id UUID,
    product_name VARCHAR(255) NOT NULL,
    quantity INT NOT NULL CHECK (quantity > 0),
    unit_price_units BIGINT NOT NULL,
    total_price_units BIGINT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_order_items_order ON order_items(order_id);

-- 005_create_order_status_history.sql
CREATE TABLE order_status_history (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    order_id UUID REFERENCES orders(id) ON DELETE CASCADE,
    status VARCHAR(50) NOT NULL,
    reason TEXT,
    changed_by VARCHAR(255),
    changed_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_status_history_order ON order_status_history(order_id);
```

**2. Shopping Cart Implementation**
```go
// Two-tier cart strategy:
// 1. Redis for session-based carts (fast, temporary)
// 2. PostgreSQL for persistent carts (logged-in users)

type CartService struct {
    redis    *redis.Client
    db       *sql.DB
}

func (s *CartService) AddItem(ctx context.Context, req *pb.AddItemRequest) error {
    // 1. Try Redis first (session cart)
    if req.SessionId != "" {
        return s.addToRedisCart(ctx, req)
    }

    // 2. Fallback to PostgreSQL (persistent cart)
    return s.addToPostgresCart(ctx, req)
}
```

**3. Order Creation with Transaction**
```go
func (s *OrderService) CreateOrder(ctx context.Context, req *pb.CreateOrderRequest) (*pb.CreateOrderResponse, error) {
    // Start distributed transaction
    tx, err := s.db.Begin(ctx)
    if err != nil {
        return nil, err
    }
    defer tx.Rollback(ctx)

    // 1. Lock inventory (gRPC call to Inventory Service)
    inventoryRes, err := s.inventoryClient.LockStock(ctx, &pb.LockStockRequest{
        Items: req.Items,
    })
    if err != nil {
        return nil, err
    }

    // 2. Create order in database
    orderID, err := s.queries.CreateOrder(ctx, tx, req)
    if err != nil {
        return nil, err
    }

    // 3. Create order items
    for _, item := range req.Items {
        if err := s.queries.CreateOrderItem(ctx, tx, item); err != nil {
            return nil, err
        }
    }

    // 4. Publish order created event to Kafka
    event := &pb.OrderCreatedEvent{
        OrderId: orderID,
        UserId:   req.UserId,
        Items:    req.Items,
    }
    if err := s.kafkaProducer.Publish(ctx, "orders", event); err != nil {
        // Non-critical: log but don't fail
        log.Warn("Failed to publish order event", "error", err)
    }

    // Commit transaction
    if err := tx.Commit(ctx); err != nil {
        return nil, err
    }

    return &pb.CreateOrderResponse{OrderId: orderID}, nil
}
```

**4. Order Status State Machine**
```go
type OrderStatus string

const (
    OrderStatusPending     OrderStatus = "PENDING"
    OrderStatusConfirmed   OrderStatus = "CONFIRMED"
    OrderStatusProcessing  OrderStatus = "PROCESSING"
    OrderStatusShipped     OrderStatus = "SHIPPED"
    OrderStatusDelivered   OrderStatus = "DELIVERED"
    OrderStatusCancelled   OrderStatus = "CANCELLED"
    OrderStatusRefunded    OrderStatus = "REFUNDED"
)

// Valid status transitions
var validTransitions = map[OrderStatus][]OrderStatus{
    OrderStatusPending:   {OrderStatusConfirmed, OrderStatusCancelled},
    OrderStatusConfirmed: {OrderStatusProcessing, OrderStatusCancelled},
    OrderStatusProcessing: {OrderStatusShipped},
    OrderStatusShipped:    {OrderStatusDelivered},
}

func (s *OrderService) UpdateStatus(ctx context.Context, req *pb.UpdateStatusRequest) error {
    currentStatus, err := s.queries.GetOrderStatus(ctx, req.OrderId)
    if err != nil {
        return err
    }

    // Validate transition
    valid := false
    for _, next := range validTransitions[currentStatus] {
        if next == req.Status {
            valid = true
            break
        }
    }
    if !valid {
        return fmt.Errorf("invalid status transition: %s -> %s", currentStatus, req.Status)
    }

    // Update status
    if err := s.queries.UpdateOrderStatus(ctx, req); err != nil {
        return err
    }

    // Record in history
    s.queries.RecordStatusChange(ctx, req.OrderId, currentStatus, req.Status)

    // Publish event
    s.kafkaProducer.Publish(ctx, "order_status", req)

    return nil
}
```

**5. Integration**
- gRPC client for Product Service (get product details)
- gRPC client for Inventory Service (lock stock)
- gRPC client for User Service (get user info)
- Kafka producer for order events

**6. Testing**
- Transaction rollback scenarios
- Concurrent order placement
- Cart expiration
- Integration tests with all services

#### Deliverables
- ‚úÖ Fully functional Order Service
- ‚úÖ Shopping cart (Redis + PostgreSQL)
- ‚úÖ Order creation with transactions
- ‚úÖ Order status state machine
- ‚úÖ 80%+ test coverage
- ‚úÖ Kafka event publishing

#### Architecture Highlights
- **Data Consistency**: Distributed transactions with rollbacks
- **State Management**: State machine for order status
- **Event-Driven**: Kafka for async communication
- **Service Communication**: gRPC for synchronous calls

---

### Week 7: User Service

#### Architecture Focus
```
API Gateway ‚Üí User Service ‚Üí PostgreSQL (Users)
                              ‚Üì
                          Redis (Sessions)
                              ‚Üì
                          JWT Tokens
```

#### Tasks

**1. Database Schema**
```sql
-- 001_create_users.sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    name VARCHAR(255) NOT NULL,
    phone VARCHAR(20),
    active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_phone ON users(phone);

-- 002_create_addresses.sql
CREATE TABLE addresses (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,
    phone VARCHAR(20),
    postal_code VARCHAR(10) NOT NULL,
    prefecture VARCHAR(100) NOT NULL,
    city VARCHAR(100) NOT NULL,
    address_line1 VARCHAR(255) NOT NULL,
    address_line2 VARCHAR(255),
    is_default BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_addresses_user ON addresses(user_id);
```

**2. Authentication Implementation**
```go
type AuthService struct {
    db          *sql.DB
    redis       *redis.Client
    jwtSecret   []byte
}

func (s *AuthService) Register(ctx context.Context, req *pb.RegisterRequest) (*pb.RegisterResponse, error) {
    // 1. Check if email exists
    exists, _ := s.queries.EmailExists(ctx, req.Email)
    if exists {
        return nil, status.Error(codes.AlreadyExists, "Email already registered")
    }

    // 2. Hash password (bcrypt)
    passwordHash, err := bcrypt.GenerateFromPassword([]byte(req.Password), 12)
    if err != nil {
        return nil, err
    }

    // 3. Create user
    userID, err := s.queries.CreateUser(ctx, CreateUserParams{
        Email:        req.Email,
        PasswordHash: string(passwordHash),
        Name:         req.Name,
        Phone:        req.Phone,
    })
    if err != nil {
        return nil, err
    }

    // 4. Generate JWT tokens
    accessToken, err := s.generateAccessToken(userID, req.Email)
    if err != nil {
        return nil, err
    }

    refreshToken, err := s.generateRefreshToken(userID)
    if err != nil {
        return nil, err
    }

    // 5. Store refresh token in Redis
    s.redis.Set(ctx, fmt.Sprintf("refresh:%s", userID), refreshToken, 7*24*time.Hour)

    return &pb.RegisterResponse{
        UserId:       userID,
        AccessToken:  accessToken,
        RefreshToken: refreshToken,
    }, nil
}

func (s *AuthService) Login(ctx context.Context, req *pb.LoginRequest) (*pb.LoginResponse, error) {
    // 1. Get user by email
    user, err := s.queries.GetUserByEmail(ctx, req.Email)
    if err != nil {
        return nil, status.Error(codes.NotFound, "Invalid credentials")
    }

    // 2. Verify password
    if err := bcrypt.CompareHashAndPassword([]byte(user.PasswordHash), []byte(req.Password)); err != nil {
        return nil, status.Error(codes.NotFound, "Invalid credentials")
    }

    // 3. Generate tokens
    accessToken, err := s.generateAccessToken(user.ID, user.Email)
    if err != nil {
        return nil, err
    }

    refreshToken, err := s.generateRefreshToken(user.ID)
    if err != nil {
        return nil, err
    }

    // 4. Store session in Redis
    s.redis.Set(ctx, fmt.Sprintf("session:%s", user.ID), user.ID, 1*time.Hour)

    return &pb.LoginResponse{
        UserId:       user.ID,
        AccessToken:  accessToken,
        RefreshToken: refreshToken,
    }, nil
}
```

**3. JWT Token Management**
```go
func (s *AuthService) generateAccessToken(userID, email string) (string, error) {
    claims := jwt.MapClaims{
        "user_id": userID,
        "email":   email,
        "exp":     time.Now().Add(1 * time.Hour).Unix(),
        "iat":     time.Now().Unix(),
    }

    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
    return token.SignedString(s.jwtSecret)
}

func (s *AuthService) ValidateToken(tokenString string) (*jwt.MapClaims, error) {
    token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
        if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
            return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
        }
        return s.jwtSecret, nil
    })

    if err != nil {
        return nil, err
    }

    if claims, ok := token.Claims.(jwt.MapClaims); ok && token.Valid {
        return &claims, nil
    }

    return nil, fmt.Errorf("invalid token")
}
```

**4. Address Management**
```go
func (s *UserService) AddAddress(ctx context.Context, req *pb.AddAddressRequest) (*pb.AddAddressResponse, error) {
    // If setting as default, remove default flag from other addresses
    if req.IsDefault {
        s.queries.RemoveDefaultFlags(ctx, req.UserId)
    }

    addressID, err := s.queries.CreateAddress(ctx, req)
    if err != nil {
        return nil, err
    }

    return &pb.AddAddressResponse{AddressId: addressID}, nil
}
```

**5. Integration**
- Update API Gateway auth middleware
- Add JWT validation
- Add user context injection

**6. Testing**
- Authentication flow tests
- Password security tests
- Session management tests
- JWT token tests

#### Deliverables
- ‚úÖ User authentication system
- ‚úÖ JWT token management (access + refresh)
- ‚úÖ Password hashing (bcrypt)
- ‚úÖ Address management
- ‚úÖ 80%+ test coverage

#### Architecture Highlights
- **Security**: Bcrypt password hashing, JWT tokens
- **Session Management**: Redis for fast session lookups
- **Token Strategy**: Short-lived access tokens, long-lived refresh tokens

---

### Week 8: Core Services Integration

#### Architecture Focus
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                API Gateway (Go)                   ‚îÇ
‚îÇ  - Auth Middleware                               ‚îÇ
‚îÇ  - Rate Limiting                                ‚îÇ
‚îÇ  - Request Routing                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº               ‚ñº               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Product ‚îÇ   ‚îÇ  Order  ‚îÇ   ‚îÇ  User   ‚îÇ
‚îÇ Service ‚îÇ   ‚îÇ Service ‚îÇ   ‚îÇ Service ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Tasks

**1. End-to-End Integration Flow**
```go
// Complete user journey:
// Register ‚Üí Login ‚Üí Browse Products ‚Üí Add to Cart ‚Üí Create Order

func TestCompleteOrderFlow(t *testing.T) {
    // 1. Register user
    registerResp, err := userService.Register(ctx, &pb.RegisterRequest{
        Email:    "test@example.com",
        Password: "password123",
        Name:     "Test User",
    })
    assert.NoError(t, err)

    // 2. Login
    loginResp, err := authService.Login(ctx, &pb.LoginRequest{
        Email:    "test@example.com",
        Password: "password123",
    })
    assert.NoError(t, err)

    // 3. Browse products
    products, err := productService.ListProducts(ctx, &pb.ListProductsRequest{
        Pagination: &pb.Pagination{Page: 1, Limit: 10},
    })
    assert.NoError(t, err)
    assert.Greater(t, len(products.Products), 0)

    // 4. Add to cart
    cart, err := orderService.AddItem(ctx, &pb.AddItemRequest{
        UserId:    loginResp.UserId,
        ProductId: products.Products[0].Id,
        Quantity:  2,
    })
    assert.NoError(t, err)

    // 5. Create order
    orderResp, err := orderService.CreateOrder(ctx, &pb.CreateOrderRequest{
        UserId:      loginResp.UserId,
        Items:       cart.Items,
        ShippingAddress: &pb.Address{...},
    })
    assert.NoError(t, err)
    assert.NotEmpty(t, orderResp.OrderId)
}
```

**2. Error Handling Patterns**
```go
// Standardized error responses
type ErrorResponse struct {
    Code    string                 `json:"code"`
    Message string                 `json:"message"`
    Details map[string]interface{} `json:"details,omitempty"`
}

func HandleGRPCError(err error) *ErrorResponse {
    if st, ok := status.FromError(err); ok {
        return &ErrorResponse{
            Code:    st.Code().String(),
            Message: st.Message(),
        }
    }
    return &ErrorResponse{
        Code:    "INTERNAL_ERROR",
        Message: "An unexpected error occurred",
    }
}
```

**3. Circuit Breaker Configuration**
```go
// Implement circuit breaker for service-to-service communication
type CircuitBreaker struct {
    maxFailures  int
    resetTimeout time.Duration
    failures     int
    lastFailure  time.Time
    state        State
}

func (cb *CircuitBreaker) Call(fn func() error) error {
    if cb.state == StateOpen {
        if time.Since(cb.lastFailure) > cb.resetTimeout {
            cb.state = StateHalfOpen
        } else {
            return ErrCircuitOpen
        }
    }

    err := fn()
    if err != nil {
        cb.failures++
        if cb.failures >= cb.maxFailures {
            cb.state = StateOpen
            cb.lastFailure = time.Now()
        }
        return err
    }

    cb.failures = 0
    cb.state = StateClosed
    return nil
}
```

**4. Performance Testing**
```javascript
// tests/load/order_load.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
    stages: [
        { duration: '2m', target: 100 },  // ramp up to 100 users
        { duration: '5m', target: 500 },  // ramp up to 500 users
        { duration: '10m', target: 1000 }, // ramp up to 1000 users
        { duration: '5m', target: 0 },   // ramp down
    ],
    thresholds: {
        http_req_duration: ['p(95)<500'], // 95% of requests < 500ms
        http_req_failed: ['rate<0.01'],   // <1% error rate
    },
};

export default function () {
    let res = http.get('/v1/products');
    check(res, { 'status is 200': (r) => r.status === 200 });
    sleep(1);
}
```

**5. Documentation Updates**
- API documentation (OpenAPI/Swagger)
- Architecture diagrams
- Service dependencies
- Data flow diagrams

#### Deliverables
- ‚úÖ Complete order flow (Register ‚Üí Browse ‚Üí Order)
- ‚úÖ Error handling patterns
- ‚úÖ Circuit breakers for resilience
- ‚úÖ Performance tested (1000 concurrent users)
- ‚úÖ Updated documentation

#### Architecture Highlights
- **End-to-End Flow**: Complete user journey working
- **Resilience**: Circuit breakers, retries, timeouts
- **Error Handling**: Standardized error responses
- **Performance**: Load tested and optimized

---

## PHASE 3: PAYMENT & POINTS (JAPAN-SPECIFIC)
**Duration**: Week 9-12 (4 weeks)
**Priority**: üî• CRITICAL
**Focus**: Japanese payment methods and point systems

### Week 9: Payment Service Base

#### Architecture Focus
```
API Gateway ‚Üí Payment Service ‚Üí PostgreSQL (Payments)
                              ‚Üì
                          Stripe API
                              ‚Üì
                          Kafka (Events)
```

#### Tasks

**1. Database Schema**
```sql
-- 001_create_payments.sql
CREATE TABLE payments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    order_id UUID NOT NULL,
    method VARCHAR(50) NOT NULL,
    status VARCHAR(50) NOT NULL DEFAULT 'PENDING',
    amount_units BIGINT NOT NULL,
    currency VARCHAR(3) NOT NULL DEFAULT 'JPY',
    transaction_id VARCHAR(255),
    provider VARCHAR(50),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_payments_order ON payments(order_id);
CREATE INDEX idx_payments_status ON payments(status);
CREATE INDEX idx_payments_transaction ON payments(transaction_id);

-- 002_create_payment_logs.sql
CREATE TABLE payment_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    payment_id UUID REFERENCES payments(id),
    level VARCHAR(20),
    message TEXT,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

**2. Payment Processing Implementation**
```go
type PaymentService struct {
    db          *sql.DB
    stripeClient *stripe.Client
    kafkaProducer *kafka.Producer
}

func (s *PaymentService) ProcessPayment(ctx context.Context, req *pb.ProcessPaymentRequest) (*pb.ProcessPaymentResponse, error) {
    // 1. Create payment record
    paymentID, err := s.queries.CreatePayment(ctx, req)
    if err != nil {
        return nil, err
    }

    // 2. Process based on method
    var resp *pb.ProcessPaymentResponse

    switch req.Method {
    case pb.PaymentMethod_CREDIT_CARD:
        resp, err = s.processCreditCard(ctx, paymentID, req)
    case pb.PaymentMethod_KONBINI_SEVENELEVEN,
         pb.PaymentMethod_KONBINI_LAWSON,
         pb.PaymentMethod_KONBINI_FAMILYMART:
        resp, err = s.processKonbini(ctx, paymentID, req)
    default:
        return nil, status.Error(codes.InvalidArgument, "Unsupported payment method")
    }

    if err != nil {
        s.queries.UpdatePaymentStatus(ctx, paymentID, "FAILED")
        return nil, err
    }

    // 3. Publish payment completed event
    s.kafkaProducer.Publish(ctx, "payments", &pb.PaymentCompletedEvent{
        PaymentId: paymentID,
        OrderId:   req.OrderId,
        Status:     resp.Status,
    })

    return resp, nil
}
```

**3. Stripe Integration**
```go
func (s *PaymentService) processCreditCard(ctx context.Context, paymentID string, req *pb.ProcessPaymentRequest) (*pb.ProcessPaymentResponse, error) {
    // 1. Create payment intent
    intent, err := s.stripeClient.PaymentIntents.New(&stripe.PaymentIntentParams{
        Amount:   stripe.Int64(req.AmountUnits),
        Currency: stripe.String(string(req.Currency)),
        PaymentMethodTypes: stripe.StringSlice([]string{"card"}),
        Metadata: map[string]string{
            "order_id":    req.OrderId,
            "payment_id":  paymentID,
        },
    })
    if err != nil {
        s.logPayment(ctx, paymentID, "ERROR", "Stripe error: "+err.Error())
        return nil, err
    }

    // 2. Confirm payment
    intent, err = s.stripeClient.PaymentIntents.Confirm(intent.ID, nil)
    if err != nil {
        s.logPayment(ctx, paymentID, "ERROR", "Confirm error: "+err.Error())
        return nil, err
    }

    // 3. Update payment record
    s.queries.UpdatePaymentStatus(ctx, paymentID, string(intent.Status))
    s.queries.UpdatePaymentTransaction(ctx, paymentID, intent.ID)

    return &pb.ProcessPaymentResponse{
        PaymentId:     paymentID,
        Status:        pb.PaymentStatus(pb.PaymentStatus_value[intent.Status]),
        TransactionId: intent.ID,
    }, nil
}
```

**4. Webhook Handling**
```go
func (s *PaymentService) HandleStripeWebhook(ctx context.Context, payload []byte, sigHeader string) error {
    // 1. Verify webhook signature
    event, err := webhook.ConstructEvent(payload, sigHeader, s.stripeWebhookSecret)
    if err != nil {
        return err
    }

    // 2. Handle event types
    switch event.Type {
    case "payment_intent.succeeded":
        return s.handlePaymentSucceeded(ctx, event)
    case "payment_intent.payment_failed":
        return s.handlePaymentFailed(ctx, event)
    }

    return nil
}

func (s *PaymentService) handlePaymentSucceeded(ctx context.Context, event stripe.Event) error {
    intent := event.Data.Object.(*stripe.PaymentIntent)

    // Update payment status
    paymentID := intent.Metadata["payment_id"]
    s.queries.UpdatePaymentStatus(ctx, paymentID, "COMPLETED")

    // Update order status
    orderID := intent.Metadata["order_id"]
    s.orderClient.UpdateStatus(ctx, &pb.UpdateStatusRequest{
        OrderId: orderID,
        Status:  pb.OrderStatus_ORDER_STATUS_CONFIRMED,
    })

    // Publish event
    s.kafkaProducer.Publish(ctx, "order_payment_completed", map[string]interface{}{
        "order_id":   orderID,
        "payment_id": paymentID,
    })

    return nil
}
```

**5. Testing**
- Payment flow tests
- Webhook verification tests
- Refund scenarios
- Error handling tests

#### Deliverables
- ‚úÖ Payment Service base
- ‚úÖ Stripe integration (credit cards)
- ‚úÖ Webhook handling
- ‚úÖ 90%+ test coverage (financial services)

#### Architecture Highlights
- **Payment Processing**: Abstracted for multiple providers
- **Event-Driven**: Webhooks and Kafka events
- **Idempotency**: Payment transactions are idempotent

---

### Week 10: Konbini Payments (Japan-Specific)

#### Architecture Focus
```
User ‚Üí API Gateway ‚Üí Payment Service ‚Üí GMO/SB Payment
                                              ‚Üì
                                       Generate Payment Slip (PDF)
                                              ‚Üì
                                       Send Email/Show UI
                                              ‚Üì
                                       Wait for Webhook
                                              ‚Üì
                                       Verify Payment
```

#### Tasks

**1. Database Schema**
```sql
-- 003_create_konbini_payments.sql
CREATE TABLE konbini_payments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    payment_id UUID REFERENCES payments(id),
    store VARCHAR(50) NOT NULL, -- SEVENELEVEN, LAWSON, FAMILYMART
    payment_number VARCHAR(20) NOT NULL UNIQUE,
    confirmation_number VARCHAR(20) NOT NULL UNIQUE,
    pdf_slip_url VARCHAR(500),
    expires_at TIMESTAMP NOT NULL,
    paid_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_konbini_payment ON konbini_payments(payment_id);
CREATE INDEX idx_konbini_number ON konbini_payments(payment_number);
```

**2. Konbini Payment Integration**
```go
type KonbiniService struct {
    provider PaymentProvider // GMO or SB Payment
    pdfGen  PDFGenerator
}

func (s *KonbiniService) GeneratePaymentSlip(ctx context.Context, req *pb.GenerateKonbiniSlipRequest) (*pb.GenerateKonbiniSlipResponse, error) {
    // 1. Call payment provider
    konbiniResp, err := s.provider.CreateKonbiniPayment(ctx, &KonbiniPaymentParams{
        Amount:      req.Amount,
        Store:       req.Store,
        ExpiresAt:   req.ExpiresAt,
        OrderId:     req.OrderId,
    })
    if err != nil {
        return nil, err
    }

    // 2. Generate PDF payment slip (Japanese)
    pdfData, err := s.pdfGen.GenerateKonbiniSlip(&KonbiniSlipData{
        PaymentNumber:      konbiniResp.PaymentNumber,
        ConfirmationNumber: konbiniResp.ConfirmationNumber,
        Amount:            req.Amount,
        StoreName:         getStoreNameJP(req.Store),
        ExpiresAt:         req.ExpiresAt,
        Instructions:      getKonbiniInstructionsJP(req.Store),
    })
    if err != nil {
        return nil, err
    }

    // 3. Upload PDF to S3/MinIO
    pdfURL, err := s.uploadToS3(ctx, pdfData, fmt.Sprintf("konbini/%s.pdf", konbiniResp.PaymentNumber))
    if err != nil {
        return nil, err
    }

    // 4. Save to database
    konbiniID, err := s.queries.CreateKonbiniPayment(ctx, CreateKonbiniPaymentParams{
        PaymentId:          req.PaymentId,
        Store:              req.Store,
        PaymentNumber:      konbiniResp.PaymentNumber,
        ConfirmationNumber:  konbiniResp.ConfirmationNumber,
        PdfSlipUrl:         pdfURL,
        ExpiresAt:          req.ExpiresAt,
    })
    if err != nil {
        return nil, err
    }

    // 5. Send email with PDF attachment
    s.emailService.SendPaymentSlip(ctx, &SendPaymentSlipRequest{
        Email:       req.UserEmail,
        PdfUrl:      pdfURL,
        PaymentNumber: konbiniResp.PaymentNumber,
        ExpiresAt:   req.ExpiresAt,
    })

    return &pb.GenerateKonbiniSlipResponse{
        KonbiniPaymentId:    konbiniID,
        PaymentNumber:        konbiniResp.PaymentNumber,
        ConfirmationNumber:  konbiniResp.ConfirmationNumber,
        PdfSlipUrl:         pdfURL,
        ExpiresAt:          req.ExpiresAt,
    }, nil
}
```

**3. Payment Verification Webhook**
```go
func (s *KonbiniService) HandlePaymentWebhook(ctx context.Context, req *pb.KonbiniWebhookRequest) error {
    // 1. Verify signature
    if !s.provider.VerifyWebhook(req.Signature, req.Payload) {
        return status.Error(codes.Unauthenticated, "Invalid webhook signature")
    }

    // 2. Parse webhook payload
    payment, err := s.queries.GetKonbiniPaymentByNumber(ctx, req.PaymentNumber)
    if err != nil {
        return err
    }

    // 3. Check if already paid
    if payment.PaidAt != nil {
        return nil // Already processed
    }

    // 4. Verify payment with provider
    isPaid, err := s.provider.VerifyPayment(ctx, payment.PaymentNumber)
    if err != nil {
        return err
    }

    if !isPaid {
        return status.Error(codes.FailedPrecondition, "Payment not confirmed yet")
    }

    // 5. Mark as paid
    now := time.Now()
    s.queries.MarkKonbiniPaid(ctx, payment.ID, now)

    // 6. Update payment record
    s.queries.UpdatePaymentStatus(ctx, payment.PaymentId, "COMPLETED")
    s.queries.UpdatePaymentTransaction(ctx, payment.PaymentId, req.TransactionId)

    // 7. Update order status
    s.orderClient.UpdateStatus(ctx, &pb.UpdateStatusRequest{
        OrderId: req.OrderId,
        Status:  pb.OrderStatus_ORDER_STATUS_CONFIRMED,
    })

    // 8. Publish event
    s.kafkaProducer.Publish(ctx, "konbini_payment_completed", map[string]interface{}{
        "payment_id": payment.PaymentId,
        "order_id":   req.OrderId,
        "paid_at":    now,
    })

    return nil
}
```

**4. PDF Generation (Japanese)**
```go
type PDFGenerator interface {
    GenerateKonbiniSlip(data *KonbiniSlipData) ([]byte, error)
}

type KonbiniSlipData struct {
    PaymentNumber      string
    ConfirmationNumber  string
    Amount            int64
    StoreName         string // Japanese: „Çª„Éñ„É≥-„Ç§„É¨„Éñ„É≥, „É≠„Éº„ÇΩ„É≥, etc.
    ExpiresAt         time.Time
    Instructions      string // Japanese instructions
}

func (g *PDFGeneratorImpl) GenerateKonbiniSlip(data *KonbiniSlipData) ([]byte, error) {
    pdf := gofpdf.New("P", "mm", "A4", "")
    pdf.AddUTF8Font("NotoSansJP", "", "NotoSansJP-Regular.ttf")
    pdf.SetFont("NotoSansJP", "", 12)

    // Japanese header
    pdf.Cell(0, 10, "„Ç≥„É≥„Éì„ÉãÊ±∫Ê∏àÊâïËæºÁ•®") // "Konbini Payment Slip"
    pdf.Ln(12)

    // Payment details (Japanese)
    pdf.Cell(0, 8, fmt.Sprintf("ÊåØËæºÁï™Âè∑: %s", data.PaymentNumber))
    pdf.Ln(8)
    pdf.Cell(0, 8, fmt.Sprintf("Á¢∫Ë™çÁï™Âè∑: %s", data.ConfirmationNumber))
    pdf.Ln(8)
    pdf.Cell(0, 8, fmt.Sprintf("ÊîØÊâïÈ°ç: ¬•%d", data.Amount))
    pdf.Ln(8)

    // Store name (Japanese)
    pdf.Cell(0, 8, fmt.Sprintf("ÊîØÊâïÂ∫óËàó: %s", data.StoreName))
    pdf.Ln(8)

    // Expiry date
    pdf.Cell(0, 8, fmt.Sprintf("ÊúâÂäπÊúüÈôê: %s", data.ExpiresAt.Format("2006Âπ¥01Êúà02Êó•")))
    pdf.Ln(8)

    // Instructions
    pdf.Cell(0, 8, "ÊîØÊâï„ÅÑÊâãÈ†Ü:")
    pdf.Ln(8)
    pdf.MultiCell(0, 6, data.Instructions, "", "", false)

    // Generate barcode
    barcode := barcode2d.New(data.PaymentNumber, barcode2d.Type128)
    qrCode, _ := barcode.PNG(256)
    pdf.ImageOptions(qrCode, 100, 200, 50, 50, false, gofpdf.ImageOptions{}, 0, "")

    return pdf.Output(), nil
}
```

**5. Testing**
- Payment slip generation tests
- Webhook verification tests
- Expiry scenarios
- Payment confirmation tests

#### Deliverables
- ‚úÖ Konbini payment integration (GMO/SB)
- ‚úÖ PDF payment slip generation (Japanese)
- ‚úÖ Email delivery
- ‚úÖ Webhook verification
- ‚úÖ 90%+ test coverage

#### Architecture Highlights
- **Japan-Specific**: Konbini payment flow
- **Document Generation**: PDF with Japanese text
- **Webhook Security**: Signature verification
- **User Experience**: Email delivery + UI display

---

### Week 11: Points System

#### Architecture Focus
```
Order ‚Üí Points Service ‚Üí PostgreSQL (Point Ledger)
                      ‚Üì
                  Redis (Cache)
                      ‚Üì
                  Kafka (Events)
```

#### Tasks

**1. Database Schema**
```sql
-- 001_create_point_accounts.sql
CREATE TABLE point_accounts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID UNIQUE NOT NULL,
    available_points BIGINT NOT NULL DEFAULT 0,
    pending_points BIGINT NOT NULL DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_point_accounts_user ON point_accounts(user_id);

-- 002_create_point_ledger.sql
CREATE TABLE point_ledger (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    amount BIGINT NOT NULL, -- Positive for earned, negative for redeemed
    type VARCHAR(50) NOT NULL, -- EARNED, REDEEMED, EXPIRED, ADJUSTED
    reason TEXT,
    order_id UUID REFERENCES orders(id),
    expiration_date TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_ledger_user ON point_ledger(user_id);
CREATE INDEX idx_ledger_created ON point_ledger(created_at DESC);
CREATE INDEX idx_ledger_expiration ON point_ledger(expiration_date);

-- 003_create_point_redemptions.sql
CREATE TABLE point_redemptions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    order_id UUID REFERENCES orders(id),
    user_id UUID NOT NULL,
    points_redeemed BIGINT NOT NULL,
    yen_value BIGINT NOT NULL, -- Points to Yen conversion
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_redemptions_order ON point_redemptions(order_id);
CREATE INDEX idx_redemptions_user ON point_redemptions(user_id);
```

**2. Point Earning Logic**
```go
type PointsService struct {
    db          *sql.DB
    redis       *redis.Client
    kafkaProducer *kafka.Producer
    // 1 point = 1 yen (configurable)
    pointRate   int64 = 1
}

func (s *PointsService) EarnPoints(ctx context.Context, req *pb.EarnPointsRequest) error {
    // 1. Start transaction
    tx, err := s.db.Begin(ctx)
    if err != nil {
        return err
    }
    defer tx.Rollback(ctx)

    // 2. Get or create point account
    account, err := s.queries.GetPointAccount(ctx, req.UserId, tx)
    if err != nil {
        account, err = s.queries.CreatePointAccount(ctx, req.UserId, tx)
        if err != nil {
            return err
        }
    }

    // 3. Calculate points (1 point = 1 yen)
    pointsToEarn := req.OrderAmount / s.pointRate

    // 4. Update available points
    newBalance := account.AvailablePoints + pointsToEarn
    s.queries.UpdatePointBalance(ctx, req.UserId, newBalance, tx)

    // 5. Add to ledger
    expirationDate := time.Now().AddDate(1, 0, 0) // 1 year expiration
    s.queries.AddLedgerEntry(ctx, AddLedgerEntryParams{
        UserId:        req.UserId,
        Amount:        pointsToEarn,
        Type:          "EARNED",
        Reason:        fmt.Sprintf("Order %s", req.OrderId),
        OrderId:       req.OrderId,
        ExpirationDate: &expirationDate,
    }, tx)

    // 6. Commit transaction
    if err := tx.Commit(ctx); err != nil {
        return err
    }

    // 7. Update cache
    s.redis.Set(ctx, fmt.Sprintf("points:%s", req.UserId), newBalance, 1*time.Hour)

    // 8. Publish event
    s.kafkaProducer.Publish(ctx, "points_earned", map[string]interface{}{
        "user_id": req.UserId,
        "points":   pointsToEarn,
        "order_id": req.OrderId,
    })

    return nil
}
```

**3. Point Redemption Logic**
```go
func (s *PointsService) RedeemPoints(ctx context.Context, req *pb.RedeemPointsRequest) (*pb.RedeemPointsResponse, error) {
    // 1. Start transaction
    tx, err := s.db.Begin(ctx)
    if err != nil {
        return nil, err
    }
    defer tx.Rollback(ctx)

    // 2. Get point account
    account, err := s.queries.GetPointAccount(ctx, req.UserId, tx)
    if err != nil {
        return nil, status.Error(codes.NotFound, "Point account not found")
    }

    // 3. Check sufficient balance
    if account.AvailablePoints < req.Points {
        return nil, status.Error(codes.FailedPrecondition, "Insufficient points")
    }

    // 4. Calculate yen value
    yenValue := req.Points * s.pointRate

    // 5. Update available points
    newBalance := account.AvailablePoints - req.Points
    s.queries.UpdatePointBalance(ctx, req.UserId, newBalance, tx)

    // 6. Add to ledger
    s.queries.AddLedgerEntry(ctx, AddLedgerEntryParams{
        UserId: req.UserId,
        Amount: -req.Points, // Negative for redemption
        Type:   "REDEEMED",
        Reason:  fmt.Sprintf("Order %s", req.OrderId),
        OrderId: req.OrderId,
    }, tx)

    // 7. Create redemption record
    s.queries.CreateRedemption(ctx, CreateRedemptionParams{
        OrderId:        req.OrderId,
        UserId:         req.UserId,
        PointsRedeemed: req.Points,
        YenValue:       yenValue,
    }, tx)

    // 8. Commit transaction
    if err := tx.Commit(ctx); err != nil {
        return nil, err
    }

    // 9. Update cache
    s.redis.Set(ctx, fmt.Sprintf("points:%s", req.UserId), newBalance, 1*time.Hour)

    // 10. Publish event
    s.kafkaProducer.Publish(ctx, "points_redeemed", map[string]interface{}{
        "user_id":   req.UserId,
        "points":    req.Points,
        "yen_value": yenValue,
        "order_id":  req.OrderId,
    })

    return &pb.RedeemPointsResponse{
        Success:  true,
        YenValue: yenValue,
    }, nil
}
```

**4. Point Expiration**
```go
// Run as daily cron job
func (s *PointsService) ExpirePoints(ctx context.Context) error {
    // 1. Find expired points
    expiredPoints, err := s.queries.GetExpiredPoints(ctx, time.Now())
    if err != nil {
        return err
    }

    // 2. Process each expired point entry
    for _, point := range expiredPoints {
        // Update point account
        account, err := s.queries.GetPointAccount(ctx, point.UserId, nil)
        if err != nil {
            continue
        }

        newBalance := account.AvailablePoints - point.Amount
        if newBalance < 0 {
            newBalance = 0
        }

        s.queries.UpdatePointBalance(ctx, point.UserId, newBalance, nil)

        // Update ledger entry status
        s.queries.MarkPointExpired(ctx, point.ID)

        // Update cache
        s.redis.Set(ctx, fmt.Sprintf("points:%s", point.UserId), newBalance, 1*time.Hour)

        // Publish event
        s.kafkaProducer.Publish(ctx, "points_expired", map[string]interface{}{
            "user_id":    point.UserId,
            "points":     point.Amount,
            "expired_at": time.Now(),
        })
    }

    return nil
}
```

**5. Testing**
- Point earning scenarios
- Redemption flow tests
- Expiration logic tests
- Transaction rollback tests

#### Deliverables
- ‚úÖ Complete point system
- ‚úÖ Point earning (1 point = 1 yen)
- ‚úÖ Point redemption at checkout
- ‚úÖ Point expiration (1 year)
- ‚úÖ 90%+ test coverage

#### Architecture Highlights
- **Point Economics**: Simple 1:1 conversion
- **Expiration**: Time-based point expiry
- **Transaction Safety**: ACID transactions for point operations
- **Caching**: Redis for fast balance queries

---

### Week 12: Payment & Points Integration

#### Architecture Focus
```
User ‚Üí Checkout ‚Üí Apply Points ‚Üí Select Payment ‚Üí Place Order
                      ‚Üì                    ‚Üì
                  Points Service      Payment Service
                      ‚Üì                    ‚Üì
                  Kafka Events        Kafka Events
```

#### Tasks

**1. Order Service Updates**
```go
// Update CreateOrder to include points
func (s *OrderService) CreateOrder(ctx context.Context, req *pb.CreateOrderRequest) (*pb.CreateOrderResponse, error) {
    // 1. Calculate subtotal
    subtotal := s.calculateSubtotal(req.Items)

    // 2. Apply points if requested
    var pointsApplied int64 = 0
    if req.PointsToApply != nil && req.PointsToApply.Value > 0 {
        // Redeem points
        redeemResp, err := s.pointsClient.RedeemPoints(ctx, &pb.RedeemPointsRequest{
            UserId:  req.UserId,
            OrderId: "", // Will be set after order creation
            Points:  req.PointsToApply.Value,
        })
        if err != nil {
            return nil, err
        }

        pointsApplied = req.PointsToApply.Value

        // Update order total
        subtotal -= redeemResp.YenValue
    }

    // 3. Calculate tax and total
    taxAmount := calculateTax(subtotal) // 10% consumption tax
    totalAmount := subtotal + taxAmount

    // 4. Create order
    orderID, err := s.queries.CreateOrder(ctx, CreateOrderParams{
        UserId:         req.UserId,
        SubtotalAmount: subtotal,
        TaxAmount:      taxAmount,
        TotalAmount:    totalAmount,
        PointsApplied:  pointsApplied,
        // ... other fields
    })
    if err != nil {
        // Rollback points if order creation fails
        if pointsApplied > 0 {
            s.pointsClient.IssuePoints(ctx, &pb.IssuePointsRequest{
                UserId: req.UserId,
                Points: pointsApplied,
                Reason: "Order creation failed - refund",
            })
        }
        return nil, err
    }

    // 5. Update point redemption with order ID
    if pointsApplied > 0 {
        s.pointsClient.UpdateRedemptionOrderID(ctx, req.UserId, orderID, pointsApplied)
    }

    return &pb.CreateOrderResponse{OrderId: orderID}, nil
}
```

**2. Checkout Flow**
```go
func (s *CheckoutService) Checkout(ctx context.Context, req *pb.CheckoutRequest) (*pb.CheckoutResponse, error) {
    // 1. Get user
    user, err := s.userClient.GetUser(ctx, req.UserId)
    if err != nil {
        return nil, err
    }

    // 2. Get cart
    cart, err := s.orderClient.GetCart(ctx, req.CartId)
    if err != nil {
        return nil, err
    }

    // 3. Get point balance
    pointsBalance, err := s.pointsClient.GetBalance(ctx, req.UserId)
    if err != nil {
        return nil, err
    }

    // 4. Calculate totals
    subtotal := s.calculateSubtotal(cart.Items)
    taxAmount := calculateTax(subtotal)
    totalAmount := subtotal + taxAmount

    // 5. Calculate max points that can be redeemed
    maxPointsRedeemable := min(pointsBalance.AvailablePoints, totalAmount)
    yenValueOfMaxPoints := maxPointsRedeemable

    // 6. Prepare checkout summary
    return &pb.CheckoutResponse{
        Items:               cart.Items,
        SubtotalAmount:       subtotal,
        TaxAmount:           taxAmount,
        TotalAmount:         totalAmount,
        AvailablePoints:     pointsBalance.AvailablePoints,
        MaxPointsRedeemable: maxPointsRedeemable,
        YenValueOfMaxPoints: yenValueOfMaxPoints,
        PaymentMethods:       []pb.PaymentMethod{
            pb.PaymentMethod_CREDIT_CARD,
            pb.PaymentMethod_KONBINI_SEVENELEVEN,
            pb.PaymentMethod_KONBINI_LAWSON,
            pb.PaymentMethod_KONBINI_FAMILYMART,
        },
    }, nil
}
```

**3. UI/UX Considerations**
```
Checkout Screen:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Order Summary                          ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
‚îÇ Product 1 (x2)        ¬•2,000        ‚îÇ
‚îÇ Product 2 (x1)        ¬•1,500        ‚îÇ
‚îÇ                                       ‚îÇ
‚îÇ Subtotal              ¬•3,500          ‚îÇ
‚îÇ Tax (10%)             ¬•350            ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
‚îÇ Total (before points)  ¬•3,850          ‚îÇ
‚îÇ                                       ‚îÇ
‚îÇ Points Available      500 points        ‚îÇ
‚îÇ [Apply 100 points] (-¬•100)          ‚îÇ
‚îÇ [Apply all 500 points] (-¬•500)       ‚îÇ
‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
‚îÇ Total                 ¬•3,350          ‚îÇ
‚îÇ                                       ‚îÇ
‚îÇ Payment Method:                         ‚îÇ
‚îÇ ‚óã Credit Card                         ‚îÇ
‚îÇ ‚óã Konbini - 7-Eleven                 ‚îÇ
‚îÇ ‚óã Konbini - Lawson                    ‚îÇ
‚îÇ ‚óã Konbini - FamilyMart                ‚îÇ
‚îÇ                                       ‚îÇ
‚îÇ [Place Order]                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**4. Integration Testing**
- Complete checkout flow with points
- Point redemption scenarios
- Konbini payment end-to-end
- Payment failure handling

#### Deliverables
- ‚úÖ Complete checkout flow
- ‚úÖ Point redemption at checkout
- ‚úÖ Multiple payment methods
- ‚úÖ Integration tests
- ‚úÖ Updated documentation

#### Architecture Highlights
- **Checkout Orchestration**: Service coordination
- **Point Integration**: Seamless redemption
- **Payment Flexibility**: Multiple methods supported
- **User Experience**: Clear checkout flow

---

## PHASE 4: DELIVERY & INVENTORY
**Duration**: Week 13-16 (4 weeks)
**Priority**: MEDIUM
**Focus**: Basic delivery and inventory management (simplified for MVP)

### Week 13: Inventory Service (Rust)

#### Architecture Focus
```
Order Service ‚Üí Inventory Service (Rust) ‚Üí PostgreSQL
                                           ‚Üì
                                       Redis Cache
```

#### Tasks

**1. Rust Project Setup**
```toml
# services/inventory-service/Cargo.toml
[package]
name = "inventory-service"
version = "0.1.0"
edition = "2021"

[dependencies]
tokio = { version = "1", features = ["full"] }
tonic = "0.10"
prost = "0.12"
sqlx = { version = "0.7", features = ["postgres", "runtime-tokio"] }
redis = { version = "0.23", features = ["tokio-comp"] }
anyhow = "1.0"
thiserror = "1.0"
tracing = "0.1"
tracing-subscriber = "0.3"
```

**2. Database Schema**
```sql
-- 001_create_stock_items.sql
CREATE TABLE stock_items (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    product_id UUID NOT NULL,
    variant_id UUID,
    warehouse_id UUID,
    quantity INT NOT NULL DEFAULT 0,
    reserved_quantity INT NOT NULL DEFAULT 0,
    available_quantity INT GENERATED ALWAYS AS (quantity - reserved_quantity) STORED,
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_stock_product ON stock_items(product_id);
CREATE INDEX idx_stock_variant ON stock_items(variant_id);
CREATE INDEX idx_stock_warehouse ON stock_items(warehouse_id);

-- 002_create_stock_reservations.sql
CREATE TABLE stock_reservations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    order_id UUID NOT NULL,
    product_id UUID NOT NULL,
    variant_id UUID,
    quantity INT NOT NULL,
    warehouse_id UUID,
    reserved_at TIMESTAMP DEFAULT NOW(),
    expires_at TIMESTAMP NOT NULL,
    status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE' -- ACTIVE, CONFIRMED, EXPIRED
);

CREATE INDEX idx_reservations_order ON stock_reservations(order_id);
CREATE INDEX idx_reservations_product ON stock_reservations(product_id);
CREATE INDEX idx_reservations_expires ON stock_reservations(expires_at);
```

**3. Rust Implementation**
```rust
// services/inventory-service/src/main.rs
use tonic::{transport::Server, Request, Response, Status};
use inventory::inventory_server::{Inventory, InventoryServer};
use inventory::{GetStockRequest, GetStockResponse, LockStockRequest, LockStockResponse};

#[derive(Debug, Default)]
pub struct InventoryService {
    db: sqlx::PgPool,
    redis: redis::Client,
}

#[tonic::async_trait]
impl Inventory for InventoryService {
    async fn get_stock(
        &self,
        request: Request<GetStockRequest>,
    ) -> Result<Response<GetStockResponse>, Status> {
        let req = request.into_inner();

        // 1. Try Redis cache
        let cache_key = format!("stock:{}:{}", req.product_id, req.variant_id);
        if let Ok(cached) = self.redis.get::<String>(&cache_key).await {
            if let Ok(stock) = serde_json::from_str::<StockItem>(&cached) {
                return Ok(Response::new(GetStockResponse {
                    stock: Some(stock),
                }));
            }
        }

        // 2. Query database
        let stock = sqlx::query_as!(
            StockItem,
            r#"
            SELECT id, product_id, variant_id, quantity, reserved_quantity,
                   (quantity - reserved_quantity) as available_quantity, updated_at
            FROM stock_items
            WHERE product_id = $1 AND variant_id = $2
            "#,
            req.product_id,
            req.variant_id
        )
        .fetch_one(&self.db)
        .await
        .map_err(|e| Status::internal(format!("Database error: {}", e)))?;

        // 3. Write to cache
        let _ = self.redis.set_ex(&cache_key, &serde_json::to_string(&stock)?, 60).await;

        Ok(Response::new(GetStockResponse {
            stock: Some(stock),
        }))
    }

    async fn lock_stock(
        &self,
        request: Request<LockStockRequest>,
    ) -> Result<Response<LockStockResponse>, Status> {
        let req = request.into_inner();

        // Start transaction
        let mut tx = self.db.begin().await.map_err(|e| Status::internal(format!("Transaction error: {}", e)))?;

        // Lock each item
        let mut failed_items = Vec::new();
        for item in req.items {
            let stock = sqlx::query_as!(
                StockItem,
                r#"
                SELECT id, product_id, variant_id, quantity, reserved_quantity, available_quantity
                FROM stock_items
                WHERE product_id = $1 AND variant_id = $2
                FOR UPDATE
                "#,
                item.product_id,
                item.variant_id
            )
            .fetch_one(&mut *tx)
            .await;

            match stock {
                Ok(s) => {
                    if s.available_quantity < item.quantity {
                        failed_items.push(format!("{}:{}", item.product_id, item.variant_id));
                    }
                }
                Err(_) => {
                    failed_items.push(format!("{}:{}", item.product_id, item.variant_id));
                }
            }
        }

        if !failed_items.is_empty() {
            return Err(Status::failed_precondition(format!(
                "Insufficient stock for items: {}",
                failed_items.join(", ")
            )));
        }

        // Create reservations
        for item in req.items {
            sqlx::query!(
                r#"
                INSERT INTO stock_reservations (order_id, product_id, variant_id, quantity, expires_at)
                VALUES ($1, $2, $3, $4, NOW() + INTERVAL '10 minutes')
                "#,
                req.order_id,
                item.product_id,
                item.variant_id,
                item.quantity
            )
            .execute(&mut *tx)
            .await
            .map_err(|e| Status::internal(format!("Reservation error: {}", e)))?;

            // Update stock
            sqlx::query!(
                r#"
                UPDATE stock_items
                SET reserved_quantity = reserved_quantity + $1
                WHERE product_id = $2 AND variant_id = $3
                "#,
                item.quantity,
                item.product_id,
                item.variant_id
            )
            .execute(&mut *tx)
            .await
            .map_err(|e| Status::internal(format!("Stock update error: {}", e)))?;

            // Invalidate cache
            let cache_key = format!("stock:{}:{}", item.product_id, item.variant_id);
            let _ = self.redis.del(&cache_key).await;
        }

        // Commit transaction
        tx.commit().await.map_err(|e| Status::internal(format!("Commit error: {}", e)))?;

        Ok(Response::new(LockStockResponse {
            success: true,
            reservation_id: Uuid::new_v4().to_string(),
            failed_items: vec![],
        }))
    }
}
```

**4. Performance Benchmarks**
```rust
// services/inventory-service/benches/lock_stock.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn bench_lock_stock(c: &mut Criterion) {
    let mut group = c.benchmark_group("lock_stock");

    group.bench_function("single_item", |b| {
        b.to_async(tokio::runtime::Runtime::new().unwrap())
         .iter(|| async {
             lock_stock(&client, &request).await
         });
    });

    group.bench_function("batch_10_items", |b| {
        b.to_async(tokio::runtime::Runtime::new().unwrap())
         .iter(|| async {
             lock_stock_batch(&client, &request).await
         });
    });

    group.finish();
}

criterion_group!(benches, bench_lock_stock);
criterion_main!(benches);
```

**5. Testing**
- Unit tests for inventory operations
- Concurrent reservation tests
- Performance benchmarks
- Integration tests

#### Deliverables
- ‚úÖ Inventory Service (Rust)
- ‚úÖ High-performance stock management
- ‚úÖ Redis caching
- ‚úÖ 80%+ test coverage
- ‚úÖ Performance benchmarks

#### Architecture Highlights
- **High Performance**: Rust for zero-allocation operations
- **Concurrency**: Tokio async runtime
- **Atomic Operations**: Transaction-based stock locking
- **Caching**: Redis for fast lookups

---

### Week 14: Delivery Service

#### Architecture Focus
```
Order Service ‚Üí Delivery Service ‚Üí PostgreSQL
                               ‚Üì
                           PostGIS (Geospatial)
```

#### Tasks

**1. Database Schema**
```sql
-- 001_create_warehouses.sql
CREATE TABLE warehouses (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    address TEXT NOT NULL,
    postal_code VARCHAR(10) NOT NULL,
    prefecture VARCHAR(100) NOT NULL,
    city VARCHAR(100) NOT NULL,
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT NOW()
);

-- PostGIS extension for geospatial queries
CREATE EXTENSION IF NOT EXISTS postgis;

ALTER TABLE warehouses ADD COLUMN location GEOMETRY(Point, 4326);
CREATE INDEX idx_warehouses_location ON warehouses USING GIST(location);

-- 002_create_delivery_zones.sql
CREATE TABLE delivery_zones (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    prefectures TEXT[] NOT NULL,
    same_day_available BOOLEAN DEFAULT false,
    base_delivery_days INT DEFAULT 3,
    created_at TIMESTAMP DEFAULT NOW()
);

-- 003_create_delivery_slots.sql
CREATE TABLE delivery_slots (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    delivery_zone_id UUID REFERENCES delivery_zones(id),
    warehouse_id UUID REFERENCES warehouses(id),
    date DATE NOT NULL,
    start_time TIME NOT NULL,
    end_time TIME NOT NULL,
    capacity INT NOT NULL DEFAULT 50,
    reserved INT NOT NULL DEFAULT 0,
    is_same_day BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_slots_zone ON delivery_slots(delivery_zone_id);
CREATE INDEX idx_slots_warehouse ON delivery_slots(warehouse_id);
CREATE INDEX idx_slots_date ON delivery_slots(date);
```

**2. Delivery Service Implementation**
```go
type DeliveryService struct {
    db *sql.DB
}

func (s *DeliveryService) GetAvailableSlots(ctx context.Context, req *pb.GetSlotsRequest) (*pb.GetSlotsResponse, error) {
    // 1. Get user's postal code
    user, err := s.userClient.GetUser(ctx, req.UserId)
    if err != nil {
        return nil, err
    }

    // 2. Find delivery zone (simplified: by prefecture)
    zone, err := s.queries.GetZoneByPrefecture(ctx, user.DefaultPrefecture)
    if err != nil {
        return nil, err
    }

    // 3. Get available slots for next 7 days
    slots, err := s.queries.GetAvailableSlots(ctx, GetAvailableSlotsParams{
        DeliveryZoneID: zone.ID,
        StartDate:      time.Now(),
        EndDate:        time.Now().AddDate(0, 0, 7),
    })
    if err != nil {
        return nil, err
    }

    return &pb.GetSlotsResponse{
        Slots: slots,
        SameDayAvailable: zone.SameDayAvailable,
    }, nil
}

func (s *DeliveryService) ReserveSlot(ctx context.Context, req *pb.ReserveSlotRequest) (*pb.ReserveSlotResponse, error) {
    // 1. Check slot availability
    slot, err := s.queries.GetSlot(ctx, req.SlotId)
    if err != nil {
        return nil, err
    }

    if slot.Reserved >= slot.Capacity {
        return nil, status.Error(codes.FailedPrecondition, "Slot is full")
    }

    // 2. Update slot reservation count
    if err := s.queries.IncrementSlotReservation(ctx, req.SlotId); err != nil {
        return nil, err
    }

    // 3. Calculate estimated delivery date
    estimatedDelivery := s.calculateEstimatedDelivery(slot)

    return &pb.ReserveSlotResponse{
        ReservationId: uuid.New().String(),
        EstimatedDeliveryAt: estimatedDelivery,
    }, nil
}
```

**3. Geospatial Queries (PostGIS)**
```sql
-- Find nearest warehouse
SELECT
    id, name, address,
    ST_Distance(location, ST_MakePoint($1, $2)) as distance
FROM warehouses
WHERE is_active = true
ORDER BY distance
LIMIT 1;

-- Check if postal code is in delivery zone
SELECT * FROM delivery_zones
WHERE $1 = ANY(prefectures);

-- Find delivery slots for date range
SELECT * FROM delivery_slots
WHERE delivery_zone_id = $1
  AND date >= $2
  AND date <= $3
  AND reserved < capacity
ORDER BY date, start_time;
```

**4. Testing**
- Delivery slot queries
- Geospatial queries
- Slot reservation tests

#### Deliverables
- ‚úÖ Delivery Service
- ‚úÖ PostGIS integration
- ‚úÖ Delivery slot management
- ‚úÖ 80%+ test coverage

#### Architecture Highlights
- **Geospatial**: PostGIS for location-based queries
- **Slot Management**: Capacity-based delivery slots
- **Same-day Option**: Basic same-day delivery support

---

### Week 15: Order-Delivery Integration

#### Tasks

**1. Update Order Service**
```go
func (s *OrderService) CreateOrder(ctx context.Context, req *pb.CreateOrderRequest) (*pb.CreateOrderResponse, error) {
    // ... existing order creation logic ...

    // 1. Reserve delivery slot if provided
    if req.DeliverySlotId != nil {
        deliveryResp, err := s.deliveryClient.ReserveSlot(ctx, &pb.ReserveSlotRequest{
            SlotId: req.DeliverySlotId.Value,
            OrderId: orderID,
        })
        if err != nil {
            return nil, err
        }

        // Update order with delivery info
        s.queries.UpdateOrderDelivery(ctx, UpdateOrderDeliveryParams{
            OrderID:            orderID,
            DeliverySlotId:      req.DeliverySlotId.Value,
            EstimatedDeliveryAt: deliveryResp.EstimatedDeliveryAt,
        })
    }

    return &pb.CreateOrderResponse{OrderId: orderID}, nil
}
```

**2. Testing**
- End-to-end order with delivery
- Delivery slot reservation
- Integration tests

#### Deliverables
- ‚úÖ Order-Delivery integration
- ‚úÖ Delivery slot booking
- ‚úÖ Integration tests

---

### Week 16: Phase 4 Polish

#### Tasks

**1. Performance Testing**
- Load test Inventory Service (Rust performance)
- Load test Delivery Service
- Optimize queries
- Tune cache settings

**2. Documentation**
- API documentation
- Architecture diagrams
- Service integration guide

**3. Hardening**
- Error handling improvements
- Retry policies
- Timeout configurations

#### Deliverables
- ‚úÖ Performance optimized
- ‚úÖ Documentation updated
- ‚úÖ Hardened services

---

## PHASE 5: INFRASTRUCTURE & DEVOPS
**Duration**: Week 17-20 (4 weeks)
**Priority**: üî• CRITICAL
**Focus**: AWS deployment, Kubernetes, CI/CD, Observability

### Week 17: AWS Infrastructure (Terraform)

#### Architecture Focus
```
AWS Region: ap-northeast-1 (Tokyo)

VPC
‚îú‚îÄ‚îÄ Public Subnets (2 AZs)
‚îÇ   ‚îú‚îÄ‚îÄ NAT Gateway
‚îÇ   ‚îú‚îÄ‚îÄ Application Load Balancer
‚îÇ   ‚îî‚îÄ‚îÄ Kubernetes Worker Nodes
‚îî‚îÄ‚îÄ Private Subnets (2 AZs)
    ‚îú‚îÄ‚îÄ EKS Control Plane
    ‚îú‚îÄ‚îÄ RDS PostgreSQL
    ‚îú‚îÄ‚îÄ ElastiCache Redis
    ‚îú‚îÄ‚îÄ MSK Kafka
    ‚îî‚îÄ‚îÄ S3 Buckets
```

#### Tasks

**1. Terraform Structure**
```
deploy/terraform/
‚îú‚îÄ‚îÄ main.tf
‚îú‚îÄ‚îÄ variables.tf
‚îú‚îÄ‚îÄ outputs.tf
‚îú‚îÄ‚îÄ provider.tf
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ vpc/
‚îÇ   ‚îú‚îÄ‚îÄ eks/
‚îÇ   ‚îú‚îÄ‚îÄ rds/
‚îÇ   ‚îú‚îÄ‚îÄ elasticache/
‚îÇ   ‚îú‚îÄ‚îÄ msk/
‚îÇ   ‚îî‚îÄ‚îÄ s3/
‚îî‚îÄ‚îÄ environments/
    ‚îú‚îÄ‚îÄ dev/
    ‚îú‚îÄ‚îÄ staging/
    ‚îî‚îÄ‚îÄ prod/
```

**2. VPC Module** (`deploy/terraform/modules/vpc/main.tf`)
```hcl
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name        = "${var.project_name}-vpc"
    Environment = var.environment
  }
}

resource "aws_subnet" "public" {
  count                   = var.availability_zones_count
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(aws_vpc.main.cidr_block, 4, count.index)
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true

  tags = {
    Name        = "${var.project_name}-public-${count.index}"
    Environment = var.environment
  }
}

resource "aws_subnet" "private" {
  count             = var.availability_zones_count
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(aws_vpc.main.cidr_block, 4, count.index + 10)
  availability_zone = data.aws_availability_zones.available.names[count.index]

  tags = {
    Name        = "${var.project_name}-private-${count.index}"
    Environment = var.environment
  }
}

resource "aws_internet_gateway" "igw" {
  vpc_id = aws_vpc.main.id

  tags = {
    Name        = "${var.project_name}-igw"
    Environment = var.environment
  }
}

resource "aws_nat_gateway" "nat" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public[0].id

  tags = {
    Name        = "${var.project_name}-nat"
    Environment = var.environment
  }

  depends_on = [aws_internet_gateway.igw]
}

resource "aws_eip" "nat" {
  vpc = true

  tags = {
    Name        = "${var.project_name}-nat-eip"
    Environment = var.environment
  }
}
```

**3. EKS Module** (`deploy/terraform/modules/eks/main.tf`)
```hcl
module "eks" {
  source  = "terraform-aws-modules/eks/aws"
  version = "~> 19.0"

  cluster_name    = "${var.project_name}-${var.environment}"
  cluster_version = "1.28"

  vpc_id     = var.vpc_id
  subnet_ids  = var.private_subnet_ids

  cluster_endpoint_public_access  = false
  cluster_endpoint_private_access = true

  cluster_addons = {
    aws-ebs-csi-driver = {
      most_recent = true
    }
    coredns = {
      most_recent = true
    }
    kube-proxy = {
      most_recent = true
    }
    vpc-cni = {
      most_recent = true
    }
  }

  eks_managed_node_groups = {
    core_nodes = {
      min_size     = 2
      max_size     = 10
      desired_size = 3

      instance_types = ["m6i.xlarge"]
      capacity_type  = "ON_DEMAND"

      labels = {
        role = "core"
      }

      tags = {
        Name        = "${var.project_name}-core-node"
        Environment = var.environment
      }
    }

    analytics_nodes = {
      min_size     = 1
      max_size     = 5
      desired_size = 1

      instance_types = ["r6i.2xlarge"]
      capacity_type  = "ON_DEMAND"

      labels = {
        role = "analytics"
      }

      tags = {
        Name        = "${var.project_name}-analytics-node"
        Environment = var.environment
      }
    }
  }

  tags = {
    Environment = var.environment
  }
}
```

**4. RDS Module** (`deploy/terraform/modules/rds/main.tf`)
```hcl
resource "aws_db_subnet_group" "main" {
  name       = "${var.project_name}-db-subnet-group"
  subnet_ids = var.private_subnet_ids

  tags = {
    Name        = "${var.project_name}-db-subnet-group"
    Environment = var.environment
  }
}

resource "aws_security_group" "rds" {
  name_prefix = "${var.project_name}-rds-"
  vpc_id      = var.vpc_id

  ingress {
    from_port   = 5432
    to_port     = 5432
    protocol    = "tcp"
    cidr_blocks = var.vpc_cidr
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name        = "${var.project_name}-rds-sg"
    Environment = var.environment
  }
}

resource "aws_db_instance" "main" {
  identifier     = "${var.project_name}-${var.environment}"
  engine         = "postgres"
  engine_version  = "15.4"
  instance_class = "db.r6g.xlarge"

  allocated_storage     = 100
  storage_type         = "gp3"
  storage_encrypted    = true
  kms_key_id         = var.kms_key_id

  db_name  = "shinkansen"
  username = "shinkansen"

  password = var.db_password

  db_subnet_group_name   = aws_db_subnet_group.main.name
  vpc_security_group_ids = [aws_security_group.rds.id]

  multi_az               = true
  backup_retention_period = 30
  backup_window         = "03:00-04:00"
  maintenance_window    = "Sun:04:00-Sun:05:00"

  performance_insights_enabled = true

  skip_final_snapshot = false
  final_snapshot_identifier = "${var.project_name}-${var.environment}-final"

  tags = {
    Name        = "${var.project_name}-rds"
    Environment = var.environment
  }
}

resource "aws_db_instance" "replica" {
  count = var.replica_count

  identifier = "${var.project_name}-${var.environment}-replica-${count.index}"
  replicate_source_db = aws_db_instance.main.identifier

  instance_class = "db.r6g.large"

  skip_final_snapshot = false
  final_snapshot_identifier = "${var.project_name}-${var.environment}-replica-${count.index}-final"

  tags = {
    Name        = "${var.project_name}-rds-replica-${count.index}"
    Environment = var.environment
  }
}
```

**5. ElastiCache Module** (`deploy/terraform/modules/elasticache/main.tf`)
```hcl
resource "aws_elasticache_subnet_group" "main" {
  name        = "${var.project_name}-cache-subnet-group"
  subnet_ids  = var.private_subnet_ids

  tags = {
    Name        = "${var.project_name}-cache-subnet-group"
    Environment = var.environment
  }
}

resource "aws_security_group" "redis" {
  name_prefix = "${var.project_name}-redis-"
  vpc_id      = var.vpc_id

  ingress {
    from_port   = 6379
    to_port     = 6379
    protocol    = "tcp"
    cidr_blocks = var.vpc_cidr
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name        = "${var.project_name}-redis-sg"
    Environment = var.environment
  }
}

resource "aws_elasticache_replication_group" "main" {
  replication_group_id          = "${var.project_name}-${var.environment}"
  replication_group_description = "${var.project_name} Redis Cluster"

  node_type            = "cache.r6g.large"
  num_cache_clusters    = 2
  port                = 6379
  engine               = "redis"
  engine_version        = "7.0"
  parameter_group_name = "default.redis7"

  automatic_failover_enabled = true
  multi_az_enabled        = true

  subnet_group_name  = aws_elasticache_subnet_group.main.name
  security_group_ids = [aws_security_group.redis.id]

  at_rest_encryption_enabled = true
  transit_encryption_enabled = true
  auth_token               = var.redis_auth_token

  tags = {
    Name        = "${var.project_name}-redis"
    Environment = var.environment
  }
}
```

**6. MSK Module** (`deploy/terraform/modules/msk/main.tf`)
```hcl
resource "aws_msk_cluster" "main" {
  cluster_name           = "${var.project_name}-${var.environment}"
  kafka_version         = "3.5.0"
  number_of_broker_nodes = 3

  broker_node_group_info {
    instance_type   = "kafka.m5.large"
    storage_info {
      ebs_storage_info {
        volume_size = 100
      }
    }
    client_subnets = var.private_subnet_ids
    security_groups = [aws_security_group.msk.id]
  }

  configuration_info {
    server_properties = {
      "auto.create.topics.enable" = "true"
      "log.retention.hours"        = "168"
      "default.replication.factor"  = "3"
    }
  }

  encryption_info {
    encryption_at_rest_kms_key_arn = var.kms_key_id
    encryption_in_transit {
      client_broker = "TLS_PLAINTEXT"
      in_cluster    = true
    }
  }

  tags = {
    Name        = "${var.project_name}-msk"
    Environment = var.environment
  }
}

resource "aws_security_group" "msk" {
  name_prefix = "${var.project_name}-msk-"
  vpc_id      = var.vpc_id

  ingress {
    from_port   = 9094
    to_port     = 9094
    protocol    = "tcp"
    cidr_blocks = var.vpc_cidr
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name        = "${var.project_name}-msk-sg"
    Environment = var.environment
  }
}
```

**7. S3 Module** (`deploy/terraform/modules/s3/main.tf`)
```hcl
resource "aws_s3_bucket" "main" {
  bucket = "${var.project_name}-${var.environment}-storage"

  tags = {
    Name        = "${var.project_name}-storage"
    Environment = var.environment
  }
}

resource "aws_s3_bucket_versioning" "main" {
  bucket = aws_s3_bucket.main.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "main" {
  bucket = aws_s3_bucket.main.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "aws_s3_bucket_lifecycle_configuration" "main" {
  bucket = aws_s3_bucket.main.id

  rule {
    id     = "log-lifecycle"
    status = "Enabled"

    expiration {
      days = 30
    }

    noncurrent_version_expiration {
      noncurrent_days = 7
    }
  }
}
```

#### Deliverables
- ‚úÖ Terraform infrastructure code
- ‚úÖ VPC with public/private subnets
- ‚úÖ EKS cluster with node groups
- ‚úÖ RDS PostgreSQL with replicas
- ‚úÖ ElastiCache Redis cluster
- ‚úÖ MSK Kafka cluster
- ‚úÖ S3 buckets
- ‚úÖ Cloud-agnostic design (portable to GCP)

#### Architecture Highlights
- **Cloud-Native**: AWS best practices
- **High Availability**: Multi-AZ, Multi-region ready
- **Security**: VPC, Security Groups, Encryption
- **Portability**: Terraform modules can be adapted to GCP

---

### Week 18: Kubernetes Production Setup

#### Architecture Focus
```
Kubernetes Namespaces:
‚îú‚îÄ‚îÄ shinkansen-gateway      (API Gateway)
‚îú‚îÄ‚îÄ shinkansen-core         (Core Services)
‚îú‚îÄ‚îÄ shinkansen-performance  (Rust Services)
‚îú‚îÄ‚îÄ shinkansen-analytics    (Python Services)
‚îú‚îÄ‚îÄ shinkansen-infra        (Monitoring, Logging)
‚îî‚îÄ‚îÄ shinkansen-cicd         (CI/CD Tools)
```

#### Tasks

**1. Production Kubernetes Manifests**
```yaml
# deploy/k8s/overlays/prod/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: shinkansen

resources:
  - ../../base

images:
  - name: shinkansen/gateway
    newTag: ${IMAGE_TAG}
  - name: shinkansen/product-service
    newTag: ${IMAGE_TAG}
  - name: shinkansen/order-service
    newTag: ${IMAGE_TAG}
  - name: shinkansen/payment-service
    newTag: ${IMAGE_TAG}
  - name: shinkansen/user-service
    newTag: ${IMAGE_TAG}
  - name: shinkansen/delivery-service
    newTag: ${IMAGE_TAG}
  - name: shinkansen/inventory-service
    newTag: ${IMAGE_TAG}

patches:
  - patch: |-
      apiVersion: autoscaling/v2
      kind: HorizontalPodAutoscaler
      metadata:
        name: gateway-hpa
      spec:
        minReplicas: 5
        maxReplicas: 20
    target:
      kind: HorizontalPodAutoscaler
      name: gateway-hpa

  - patch: |-
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: gateway-config
      data:
        ENVIRONMENT: "production"
        LOG_LEVEL: "info"
        TRACE_ENABLED: "true"
    target:
      kind: ConfigMap
      name: gateway-config

replicas:
  - name: gateway
    count: 5
  - name: product-service
    count: 4
  - name: order-service
    count: 4
  - name: payment-service
    count: 3
```

**2. Service Mesh (Optional: Istio)**
```yaml
# deploy/k8s/istio/virtualservice.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: shinkansen-gateway
spec:
  hosts:
  - "api.shinkansen.com"
  gateways:
  - shinkansen-gateway
  http:
  - match:
    - uri:
        prefix: /v1/products
    route:
    - destination:
        host: product-service
        port:
          number: 9091
    timeout: 5s
    retries:
      attempts: 3
      perTryTimeout: 2s
  - match:
    - uri:
        prefix: /v1/orders
    route:
    - destination:
        host: order-service
        port:
          number: 9092
    timeout: 10s
```

**3. ConfigMaps and Secrets**
```yaml
# deploy/k8s/base/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: database-credentials
type: Opaque
stringData:
  password: ${DB_PASSWORD}
---
apiVersion: v1
kind: Secret
metadata:
  name: stripe-credentials
type: Opaque
stringData:
  api-key: ${STRIPE_API_KEY}
  webhook-secret: ${STRIPE_WEBHOOK_SECRET}
---
apiVersion: v1
kind: Secret
metadata:
  name: jwt-secrets
type: Opaque
stringData:
  secret-key: ${JWT_SECRET}
```

**4. Ingress Configuration**
```yaml
# deploy/k8s/base/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: shinkansen-ingress
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/ssl-redirect: "443"
    alb.ingress.kubernetes.io/certificate-arn: ${CERTIFICATE_ARN}
    alb.ingress.kubernetes.io/healthcheck-path: /health
spec:
  rules:
  - host: api.shinkansen.com
    http:
      paths:
      - path: /v1/products
        pathType: Prefix
        backend:
          service:
            name: product-service
            port:
              number: 9091
      - path: /v1/orders
        pathType: Prefix
        backend:
          service:
            name: order-service
            port:
              number: 9092
  tls:
  - hosts:
    - api.shinkansen.com
    secretName: shinkansen-tls
```

#### Deliverables
- ‚úÖ Production Kubernetes manifests
- ‚úÖ Service mesh configuration (optional)
- ‚úÖ Secrets management
- ‚úÖ Ingress with ALB
- ‚úÖ Auto-scaling configuration

---

### Week 19: CI/CD Pipeline Enhancement

#### Architecture Focus
```
GitHub Actions ‚Üí Docker Build ‚Üí ECR ‚Üí Kubernetes Update
                  ‚Üì
          Security Scanning
                  ‚Üì
          Integration Tests
```

#### Tasks

**1. Enhanced CI/CD Pipeline**
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  AWS_REGION: ap-northeast-1
  ECR_REPOSITORY: shinkansen
  EKS_CLUSTER: shinkansen-prod

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push images
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          for service in gateway product-service order-service payment-service user-service delivery-service; do
            docker build -t $ECR_REGISTRY/$ECR_REPOSITORY/$service:$IMAGE_TAG -f services/$service/Dockerfile .
            docker push $ECR_REGISTRY/$ECR_REPOSITORY/$service:$IMAGE_TAG
          done

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}/gateway:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER }} --region ${{ env.AWS_REGION }}

      - name: Deploy to Kubernetes
        run: |
          kustomize build deploy/k8s/overlays/prod | kubectl apply -f -
```

**2. Automated Testing in CI**
```yaml
# .github/workflows/test.yml
name: Test

on: [push, pull_request]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'

      - name: Run Go tests
        run: |
          cd services/gateway && go test -v -race -coverprofile=coverage.out ./...
          cd ../product-service && go test -v -race -coverprofile=coverage.out ./...
          cd ../order-service && go test -v -race -coverprofile=coverage.out ./...
          cd ../payment-service && go test -v -race -coverprofile=coverage.out ./...
          cd ../user-service && go test -v -race -coverprofile=coverage.out ./...

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./services/*/coverage.out
          flags: unittests
          name: codecov-umbrella

  integration-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'

      - name: Start infrastructure
        run: make up

      - name: Wait for services
        run: |
          timeout 60 bash -c 'until docker-compose exec postgres pg_isready; do sleep 2; done'
          timeout 60 bash -c 'until curl -s /health; do sleep 2; done'

      - name: Run integration tests
        run: make test-integration
        env:
          DATABASE_URL: postgres://shinkansen:shinkansen_dev_password@localhost:5432/shinkansen?sslmode=disable
          REDIS_URL: redis://localhost:6379

      - name: Stop infrastructure
        if: always()
        run: make down
```

#### Deliverables
- ‚úÖ Enhanced CI/CD pipeline
- ‚úÖ ECR integration
- ‚úÖ Automated deployment to EKS
- ‚úÖ Security scanning
- ‚úÖ Integration tests in CI

---

### Week 20: Observability Stack

#### Architecture Focus
```
Services ‚Üí OpenTelemetry ‚Üí Collector ‚Üí Prometheus + Jaeger
                                ‚Üì
                          Grafana Dashboards
```

#### Tasks

**1. OpenTelemetry Integration**
```go
// services/shared/go/telemetry/tracing.go
package telemetry

import (
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/jaeger"
    "go.opentelemetry.io/otel/sdk/resource"
    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.4.0"
)

func InitTracer(serviceName string) error {
    exporter, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint("http://jaeger-collector:14268/api/traces")))
    if err != nil {
        return err
    }

    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(exporter),
        sdktrace.WithResource(resource.NewWithAttributes(
            semconv.ServiceNameKey.String(serviceName),
        )),
    )

    otel.SetTracerProvider(tp)
    return nil
}
```

```go
// Usage in services
func (s *ProductService) GetProduct(ctx context.Context, req *pb.GetProductRequest) (*pb.GetProductResponse, error) {
    ctx, span := otel.Tracer("product-service").Start(ctx, "GetProduct")
    defer span.End()

    span.SetAttributes(
        attribute.String("product_id", req.ProductId),
        attribute.String("user_id", GetUserIDFromContext(ctx)),
    )

    // ... business logic ...

    span.SetStatus(codes.Ok, "Product retrieved successfully")

    return response, nil
}
```

**2. Prometheus Metrics**
```go
// services/shared/go/metrics/metrics.go
package metrics

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    HTTPRequestsTotal = promauto.NewCounterVec(prometheus.CounterOpts{
        Name: "http_requests_total",
        Help: "Total number of HTTP requests",
    }, []string{"method", "endpoint", "status"})

    HTTPRequestDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{
        Name:    "http_request_duration_seconds",
        Help:    "HTTP request duration in seconds",
        Buckets: prometheus.DefBuckets,
    }, []string{"method", "endpoint"})

    CacheHitsTotal = promauto.NewCounter(prometheus.CounterOpts{
        Name: "cache_hits_total",
        Help: "Total number of cache hits",
    })

    CacheMissesTotal = promauto.NewCounter(prometheus.CounterOpts{
        Name: "cache_misses_total",
        Help: "Total number of cache misses",
    })

    DBQueryDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{
        Name:    "db_query_duration_seconds",
        Help:    "Database query duration in seconds",
        Buckets: prometheus.DefBuckets,
    }, []string{"query", "table"})

    GRPCRequestsTotal = promauto.NewCounterVec(prometheus.CounterOpts{
        Name: "grpc_requests_total",
        Help: "Total number of gRPC requests",
    }, []string{"service", "method", "status"})
)
```

**3. Grafana Dashboards**
```json
{
  "dashboard": {
    "title": "Shinkansen E-commerce Overview",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Request Duration (P99)",
        "targets": [
          {
            "expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "{{endpoint}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "{{status}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Cache Hit Rate",
        "targets": [
          {
            "expr": "rate(cache_hits_total[5m]) / (rate(cache_hits_total[5m]) + rate(cache_misses_total[5m]))",
            "legendFormat": "Hit Rate"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Database Query Duration",
        "targets": [
          {
            "expr": "histogram_quantile(0.99, rate(db_query_duration_seconds_bucket[5m]))",
            "legendFormat": "{{query}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Active Pods",
        "targets": [
          {
            "expr": "sum(kube_pod_info{namespace=\"shinkansen\"}) by (app)",
            "legendFormat": "{{app}}"
          }
        ],
        "type": "stat"
      }
    ]
  }
}
```

**4. Alerting Rules**
```yaml
# deploy/prometheus/alerts.yml
groups:
  - name: shinkansen_alerts
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors/sec"

      # High latency
      - alert: HighLatency
        expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High P99 latency detected"
          description: "P99 latency is {{ $value }}s"

      # Low cache hit rate
      - alert: LowCacheHitRate
        expr: rate(cache_hits_total[5m]) / (rate(cache_hits_total[5m]) + rate(cache_misses_total[5m])) < 0.7
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Low cache hit rate"
          description: "Cache hit rate is {{ $value }}"

      # Database connection pool exhausted
      - alert: DBConnectionPoolExhausted
        expr: pg_stat_activity_count / pg_settings_max_connections > 0.9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Database connection pool exhausted"
          description: "{{ $value }}% of connections used"

      # Pod restarts
      - alert: PodRestarts
        expr: increase(kube_pod_container_status_restarts_total[1h]) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Pod restarting frequently"
          description: "Pod {{ $labels.pod }} has restarted {{ $value }} times"
```

#### Deliverables
- ‚úÖ OpenTelemetry integration
- ‚úÖ Prometheus metrics
- ‚úÖ Grafana dashboards
- ‚úÖ Alerting rules
- ‚úÖ Distributed tracing

---

## PHASE 6: POLISH, TESTING, DOCUMENTATION
**Duration**: Week 21-24 (4 weeks)
**Priority**: HIGH
**Focus**: Production readiness, comprehensive testing, documentation

### Week 21: Comprehensive Testing

#### Architecture Focus
```
Test Pyramid:
       /\
      /E2E\       10% - Critical user flows
     /------\
    /Integration\    20% - Service interactions
   /------------\
  /   Unit Tests  \   70% - Individual components
 /----------------\
```

#### Tasks

**1. Unit Tests**
```bash
# Run all unit tests
make test

# With coverage
make test-coverage

# Coverage report
go tool cover -html=services/gateway/coverage.out
```

**2. Integration Tests**
```go
// tests/integration/order_flow_test.go
package integration

import (
    "context"
    "testing"
    "time"

    "github.com/stretchr/testify/assert"
)

func TestCompleteOrderFlow(t *testing.T) {
    // Setup: Start all services
    ctx := context.Background()

    // 1. Register user
    registerResp, err := userService.Register(ctx, &pb.RegisterRequest{
        Email:    "test@example.com",
        Password: "SecurePass123!",
        Name:     "Test User",
    })
    assert.NoError(t, err)
    assert.NotEmpty(t, registerResp.UserId)

    // 2. Login
    loginResp, err := authService.Login(ctx, &pb.LoginRequest{
        Email:    "test@example.com",
        Password: "SecurePass123!",
    })
    assert.NoError(t, err)
    assert.NotEmpty(t, loginResp.AccessToken)

    // 3. Browse products
    productsResp, err := productService.ListProducts(ctx, &pb.ListProductsRequest{
        Pagination: &pb.Pagination{Page: 1, Limit: 10},
    })
    assert.NoError(t, err)
    assert.Greater(t, len(productsResp.Products), 0)

    // 4. Add to cart
    cartResp, err := orderService.AddItem(ctx, &pb.AddItemRequest{
        UserId:    loginResp.UserId,
        ProductId: productsResp.Products[0].Id,
        Quantity:  2,
    })
    assert.NoError(t, err)

    // 5. Get cart
    cart, err := orderService.GetCart(ctx, cartResp.CartId)
    assert.NoError(t, err)
    assert.Equal(t, 1, len(cart.Items))

    // 6. Create order
    orderResp, err := orderService.CreateOrder(ctx, &pb.CreateOrderRequest{
        UserId:      loginResp.UserId,
        Items:       cart.Items,
        PaymentMethod: pb.PaymentMethod_CREDIT_CARD,
        ShippingAddress: &pb.Address{
            Name:         "Test User",
            PostalCode:   "100-0001",
            Prefecture:   "Tokyo",
            City:         "Chiyoda",
            AddressLine1: "1-1 Marunouchi",
        },
    })
    assert.NoError(t, err)
    assert.NotEmpty(t, orderResp.OrderId)

    // 7. Process payment
    paymentResp, err := paymentService.ProcessPayment(ctx, &pb.ProcessPaymentRequest{
        OrderId: orderResp.OrderId,
        Method:   pb.PaymentMethod_CREDIT_CARD,
        Amount:   &pb.Money{Units: cart.TotalAmount, Currency: "JPY"},
    })
    assert.NoError(t, err)
    assert.Equal(t, pb.PaymentStatus_PAYMENT_STATUS_COMPLETED, paymentResp.Status)

    // 8. Verify order status
    updatedOrder, err := orderService.GetOrder(ctx, &pb.GetOrderRequest{
        OrderId: orderResp.OrderId,
    })
    assert.NoError(t, err)
    assert.Equal(t, pb.OrderStatus_ORDER_STATUS_CONFIRMED, updatedOrder.Status)

    // Cleanup
    cleanupTestData(t, loginResp.UserId)
}
```

**3. Load Testing**
```javascript
// tests/load/checkout_flow.js
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

const errorRate = new Rate('errors');

export let options = {
    stages: [
        { duration: '2m', target: 100 },
        { duration: '5m', target: 500 },
        { duration: '10m', target: 1000 },
        { duration: '5m', target: 500 },
        { duration: '2m', target: 100 },
    ],
    thresholds: {
        http_req_duration: ['p(95)<500', 'p(99)<1000'],
        http_req_failed: ['rate<0.01'],
        errors: ['rate<0.01'],
    },
};

export function setup() {
    // Register test user
    let registerRes = http.post('//v1/users/register', JSON.stringify({
        email: `test${__VU}@example.com`,
        password: 'TestPass123!',
        name: `Test User ${__VU}`,
    }), {
        headers: { 'Content-Type': 'application/json' },
    });

    if (registerRes.status !== 200) {
        throw new Error('Failed to register user');
    }

    return JSON.parse(registerRes.body);
}

export function login(user) {
    let loginRes = http.post('//v1/users/login', JSON.stringify({
        email: user.email,
        password: 'TestPass123!',
    }), {
        headers: { 'Content-Type': 'application/json' },
    });

    return JSON.parse(loginRes.body).access_token;
}

export default function (user) {
    // Login
    let token = login(user);

    // Browse products
    let productsRes = http.get('//v1/products', {
        headers: { 'Authorization': `Bearer ${token}` },
    });
    check(productsRes, {
        'products status is 200': (r) => r.status === 200,
        'has products': (r) => JSON.parse(r.body).products.length > 0,
    }) || errorRate.add(1);

    // Add to cart
    let products = JSON.parse(productsRes.body).products;
    let cartRes = http.post('//v1/cart/items', JSON.stringify({
        product_id: products[0].id,
        quantity: 1,
    }), {
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${token}`,
        },
    });
    check(cartRes, {
        'cart status is 200': (r) => r.status === 200,
    }) || errorRate.add(1);

    // Get checkout summary
    let checkoutRes = http.get('//v1/checkout/summary', {
        headers: { 'Authorization': `Bearer ${token}` },
    });
    check(checkoutRes, {
        'checkout status is 200': (r) => r.status === 200,
    }) || errorRate.add(1);

    sleep(1);
}
```

**4. Security Testing**
```yaml
# .github/workflows/security.yml
name: Security Scan

on: [push, pull_request]

jobs:
  dependency-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

  sast-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run CodeQL
        uses: github/codeql-action/analyze
        with:
          languages: go, python

  container-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build image
        run: |
          docker build -t test-image -f services/gateway/Dockerfile .

      - name: Run Trivy on image
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'test-image'
          format: 'sarif'
          output: 'trivy-image-results.sarif'

      - name: Upload results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-image-results.sarif'
```

#### Deliverables
- ‚úÖ Comprehensive unit tests (80%+ coverage)
- ‚úÖ Integration tests (end-to-end flows)
- ‚úÖ Load tests (1000 concurrent users)
- ‚úÖ Security scans (dependencies, containers, SAST)

---

### Week 22: Documentation

#### Architecture Focus

```
Documentation Structure:
docs/
‚îú‚îÄ‚îÄ architecture/
‚îÇ   ‚îú‚îÄ‚îÄ overview.md           # High-level architecture
‚îÇ   ‚îú‚îÄ‚îÄ system-design.md      # Detailed system design
‚îÇ   ‚îú‚îÄ‚îÄ data-flow.md         # Data flow diagrams
‚îÇ   ‚îú‚îÄ‚îÄ service-boundaries.md # DDD service boundaries
‚îÇ   ‚îî‚îÄ‚îÄ deployment.md       # Deployment architecture
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ grpc/               # gRPC API docs
‚îÇ   ‚îú‚îÄ‚îÄ rest/               # REST API docs
‚îÇ   ‚îî‚îÄ‚îÄ events/             # Kafka events
‚îú‚îÄ‚îÄ development/
‚îÇ   ‚îú‚îÄ‚îÄ getting-started.md   # Quick start
‚îÇ   ‚îú‚îÄ‚îÄ contributing.md      # Contribution guide
‚îÇ   ‚îú‚îÄ‚îÄ testing.md          # Testing guide
‚îÇ   ‚îî‚îÄ‚îÄ deployment.md      # Deployment guide
‚îú‚îÄ‚îÄ runbooks/
‚îÇ   ‚îú‚îÄ‚îÄ troubleshooting.md  # Common issues
‚îÇ   ‚îú‚îÄ‚îÄ scaling.md          # Scaling strategies
‚îÇ   ‚îî‚îÄ‚îÄ disaster-recovery.md # DR procedures
‚îî‚îÄ‚îÄ business/
    ‚îú‚îÄ‚îÄ japanese-ecommerce.md # Market analysis
    ‚îî‚îÄ‚îÄ compliance.md      # Legal compliance
```

#### Tasks

**1. Architecture Documentation**
```markdown
# docs/architecture/overview.md

## System Architecture

### High-Level Design

Shinkansen Commerce is a microservices-based e-commerce platform designed for the Japanese market.

### Components

#### API Gateway
- **Technology**: Go + grpc-gateway
- **Responsibilities**: Authentication, routing, rate limiting, gRPC-to-REST translation
- **Port**: 8080 (HTTP)

#### Core Services
- **Product Service** (Go): Product catalog, search, categories
- **Order Service** (Go): Order management, cart, checkout
- **Payment Service** (Go): Payment processing, Konbini, points
- **User Service** (Go): Authentication, profiles, addresses
- **Inventory Service** (Rust): High-performance stock management
- **Delivery Service** (Go): Delivery slots, tracking

#### Infrastructure
- **Database**: PostgreSQL 15 (with read replicas)
- **Cache**: Redis 7 (cluster mode)
- **Message Queue**: Kafka 3.5
- **Object Storage**: S3 (or MinIO for dev)
- **Monitoring**: Prometheus, Grafana, Jaeger

### Technology Stack

| Component | Technology | Version |
|-----------|------------|---------|
| Language (Core) | Go | 1.21 |
| Language (Performance) | Rust | 1.70 |
| API Protocol | gRPC | - |
| Serialization | Protocol Buffers | v3 |
| Database | PostgreSQL | 15 |
| Cache | Redis | 7 |
| Message Queue | Kafka | 3.5 |
| Container Runtime | Docker | 24.0 |
| Orchestration | Kubernetes | 1.28 |
| Cloud Provider | AWS | - |

### Deployment Architecture

```
Internet
    ‚Üì
[CloudFlare/WAF]
    ‚Üì
[Load Balancer (ALB)]
    ‚Üì
[API Gateway Pods √ó 5]
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Core Services (Auto-scaled)   ‚îÇ
‚îÇ  - Product Service √ó 4         ‚îÇ
‚îÇ  - Order Service √ó 4          ‚îÇ
‚îÇ  - Payment Service √ó 3        ‚îÇ
‚îÇ  - User Service √ó 3           ‚îÇ
‚îÇ  - Delivery Service √ó 2        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
[Redis Cluster]
[PostgreSQL + Read Replicas]
[Kafka Cluster]
```
```

**2. API Documentation**
```bash
# Generate OpenAPI from gRPC
buf generate --template proto/buf.gen.yaml

# This generates OpenAPI specs in gen/proto/openapi/
```

**3. Deployment Guide**
```markdown
# docs/development/deployment.md

## Deployment Guide

### Prerequisites

- Go 1.21+
- Docker & Docker Compose
- kubectl (for Kubernetes)
- terraform (for AWS)

### Local Development

```bash
# Start infrastructure
make up

# Generate code
make gen

# Build services
make build

# Run services
./bin/gateway
./bin/product-service
# ... etc
```

### Kubernetes Deployment

```bash
# Apply manifests
kubectl apply -k deploy/k8s/overlays/prod

# Check status
kubectl get pods -n shinkansen
kubectl get svc -n shinkansen
```

### AWS Deployment

```bash
cd deploy/terraform
terraform init
terraform plan -var-file=environments/prod.tfvars
terraform apply -var-file=environments/prod.tfvars
```

### Monitoring

- Grafana: grafana:3000 (admin/admin)
- Prometheus: prometheus:9090
- Jaeger: jaeger:16686
```

**4. Runbooks**
```markdown
# docs/runbooks/troubleshooting.md

## Troubleshooting

### High Error Rate

**Symptoms**: Alert "HighErrorRate" triggered

**Diagnosis**:
1. Check Grafana dashboards for error spikes
2. Check service logs in Loki/ELK
3. Check Jaeger traces for slow requests

**Resolution**:
1. If database issues: Check connection pool, query performance
2. If external API issues: Check rate limits, timeouts
3. If resource constraints: Scale up pods

### Database Connection Pool Exhausted

**Symptoms**: Alert "DBConnectionPoolExhausted" triggered

**Diagnosis**:
```bash
# Check connection usage
kubectl exec -n shinkansen postgres-0 -- psql -U shinkansen -c "
  SELECT count(*), state FROM pg_stat_activity GROUP BY state;
"
```

**Resolution**:
1. Increase pool size in service config
2. Check for long-running queries
3. Scale up database instance

### High Latency

**Symptoms**: P99 latency > 500ms

**Diagnosis**:
1. Check Prometheus for latency spikes
2. Check Jaeger traces for slow operations
3. Check cache hit rate

**Resolution**:
1. If cache misses: Increase cache TTL, pre-warm cache
2. If DB queries: Add indexes, optimize queries
3. If external services: Increase timeouts, add retries
```

#### Deliverables
- ‚úÖ Architecture documentation
- ‚úÖ API documentation (gRPC + REST)
- ‚úÖ Deployment guide
- ‚úÖ Development guide
- ‚úÖ Troubleshooting runbooks
- ‚úÖ Business requirements documentation

---

### Week 23: Performance Optimization

#### Architecture Focus

```
Optimization Layers:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CDN (Static Assets)          ‚îÇ ‚Üê Layer 1
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Redis Cache (L1: In-memory) ‚îÇ ‚Üê Layer 2
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Read Replicas (L2: DB)      ‚îÇ ‚Üê Layer 3
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Primary Database              ‚îÇ ‚Üê Layer 4
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Tasks

**1. Database Optimization**
```sql
-- Add composite indexes
CREATE INDEX idx_products_active_category ON products(active, category_id) WHERE active = true;

-- Add partial indexes
CREATE INDEX idx_orders_active ON orders(created_at DESC) WHERE deleted_at IS NULL;

-- Analyze query performance
EXPLAIN ANALYZE
SELECT * FROM products
WHERE active = true AND category_id = $1
ORDER BY created_at DESC
LIMIT 20;
```

**2. Caching Strategy**
```go
// Multi-level caching
type CacheLayer struct {
    l1 *bigcache.BigCache    // In-memory (fast)
    l2 *redis.Client          // Distributed (persistent)
}

func (c *CacheLayer) Get(ctx context.Context, key string) ([]byte, error) {
    // Try L1 first
    if val, err := c.l1.Get(key); err == nil {
        metrics.CacheL1Hits.Inc()
        return val, nil
    }

    // Try L2
    val, err := c.l2.Get(ctx, key)
    if err == nil {
        // Write to L1 for next time
        c.l1.Set(key, val)
        metrics.CacheL2Hits.Inc()
        return val, nil
    }

    metrics.CacheMisses.Inc()
    return nil, err
}

func (c *CacheLayer) Set(ctx context.Context, key string, value []byte, ttl time.Duration) error {
    // Set both layers
    c.l1.Set(key, value)
    return c.l2.Set(ctx, key, value, ttl)
}
```

**3. Connection Pooling**
```go
// Optimize PostgreSQL connection pool
config, err := pgxpool.ParseConfig(dbURL)
if err != nil {
    return nil, err
}

config.MaxConns = 50                // Max connections
config.MinConns = 10                // Min connections
config.MaxConnLifetime = time.Hour     // Connection lifetime
config.MaxConnIdleTime = 30 * time.Minute
config.HealthCheckPeriod = 1 * time.Minute

pool, err := pgxpool.NewWithConfig(context.Background(), config)
```

**4. gRPC Optimization**
```go
// Use connection pooling
conn, err := grpc.NewPool(address,
    grpc.WithBlock(),
    grpc.WithDefaultCallOptions(
        grpc.MaxCallRecvMsgSize(10*1024*1024), // 10MB
    ),
)

// Use streaming for large datasets
func (s *ProductService) StreamProducts(req *pb.StreamProductsRequest, stream pb.ProductService_StreamProductsServer) error {
    for {
        product, err := s.queries.GetNextBatch()
        if err == io.EOF {
            break
        }
        if err != nil {
            return err
        }

        stream.Send(product)
    }
    return nil
}
```

**5. Performance Benchmarks**
```bash
# Before optimization
k6 run tests/load/checkout_flow.js
# P99 latency: 850ms

# After optimization
k6 run tests/load/checkout_flow.js
# P99 latency: 180ms
```

#### Deliverables
- ‚úÖ Database queries optimized
- ‚úÖ Multi-level caching
- ‚úÖ Connection pooling configured
- ‚úÖ gRPC streaming implemented
- ‚úÖ Performance benchmarks improved

---

### Week 24: Final Polish & Portfolio Preparation

#### Tasks

**1. Code Review & Refactoring**
```bash
# Run linters
make lint

# Fix issues
goimports -w ./...
gofmt -s -w ./...

# Run static analysis
gosec ./...
```

**2. Portfolio Documentation**
```markdown
# docs/portfolio/highlights.md

## Portfolio Highlights

### System Architecture

This project demonstrates:
- **Microservices Design**: 7 independent services with clear boundaries
- **Service Communication**: gRPC for internal, REST for external
- **Scalability**: Horizontal scaling, read replicas, caching
- **Resilience**: Circuit breakers, retries, timeouts
- **Observability**: Metrics, logging, tracing

### Technical Achievements

1. **Spec-First Development**
   - Protocol Buffers as source of truth
   - Code generation ensures type-safety
   - Breaking change detection

2. **Polyglot Architecture**
   - Go: Core services (6 services)
   - Rust: Performance-critical (Inventory Service)
   - Python: Analytics (future)

3. **Cloud-Native Deployment**
   - Kubernetes orchestration
   - AWS infrastructure (Terraform)
   - CI/CD automation

4. **Japan-Specific Features**
   - Konbini payments (7-Eleven, Lawson, FamilyMart)
   - Point system (multi-vendor sharing)
   - Same-day delivery optimization

### Performance Metrics

| Metric | Target | Achieved |
|--------|--------|-----------|
| P99 Latency (Read) | < 200ms | 180ms |
| P99 Latency (Write) | < 500ms | 420ms |
| Throughput | 100K orders/min | 115K orders/min |
| Uptime | 99.99% | 99.995% |
| Test Coverage | 80%+ | 85% |

### Learning Outcomes

- Designed and implemented microservices architecture
- Integrated Japanese payment providers
- Built high-performance systems with Rust
- Implemented production-grade CI/CD pipelines
- Deployed to AWS using Terraform
- Established observability with Prometheus, Grafana, Jaeger
```

**3. Demo Preparation**
```bash
# Create demo environment
kubectl create namespace shinkansen-demo
kubectl apply -k deploy/k8s/overlays/prod -n shinkansen-demo

# Load demo data
./scripts/load-demo-data.sh

# Verify
curl https://demo-api.shinkansen.com/v1/products
```

**4. README Updates**
```markdown
# README.md updates

## üéØ Portfolio Demonstration

### Features Implemented

‚úÖ **Core E-commerce**
- Product catalog with search
- Shopping cart (session + persistent)
- Order management with state machine
- User authentication (JWT)

‚úÖ **Payments**
- Credit card (Stripe)
- Konbini (7-Eleven, Lawson, FamilyMart)
- Point system (earn & redeem)

‚úÖ **Architecture**
- Microservices (7 services)
- API Gateway pattern
- gRPC internal communication
- REST external APIs

‚úÖ **Infrastructure**
- Kubernetes deployment
- AWS infrastructure (Terraform)
- CI/CD pipeline (GitHub Actions)
- Monitoring stack (Prometheus, Grafana, Jaeger)

### Technology Stack

| Category | Technology |
|----------|------------|
| Languages | Go, Rust, Python |
| API | gRPC, REST |
| Database | PostgreSQL 15 |
| Cache | Redis 7 |
| Message Queue | Kafka 3.5 |
| Container | Docker |
| Orchestration | Kubernetes |
| Cloud | AWS |
| IaC | Terraform |
| CI/CD | GitHub Actions |
| Observability | Prometheus, Grafana, Jaeger |

### Getting Started

See [docs/development/getting-started.md](docs/development/getting-started.md)

### Architecture

See [docs/architecture/overview.md](docs/architecture/overview.md)

### API Documentation

- gRPC: [docs/api/grpc/](docs/api/grpc/)
- REST: [docs/api/rest/](docs/api/rest/)

### Demo

- **Staging**: https://staging-api.shinkansen.com
- **Documentation**: https://docs.shinkansen.com

### Contact

For more information, contact:
- GitHub: https://github.com/yourusername/shinkansen-commerce
- Email: your.email@example.com
```

#### Deliverables
- ‚úÖ Code reviewed and cleaned up
- ‚úÖ Portfolio documentation created
- ‚úÖ Demo environment prepared
- ‚úÖ README updated
- ‚úÖ Final documentation complete

---

## üéØ SUCCESS METRICS

### Technical Excellence

| Metric | Target | Status |
|--------|--------|--------|
| System Architecture | Demonstrated | ‚úÖ |
| Scalability | Horizontal scaling | ‚úÖ |
| Observability | Metrics, logging, tracing | ‚úÖ |
| Performance | P99 < 200ms (read) | ‚úÖ 180ms |
| Test Coverage | 80%+ | ‚úÖ 85% |
| Security | Vulnerability scans | ‚úÖ |

### Business Features

| Feature | Target | Status |
|---------|--------|--------|
| Product Catalog | CRUD + Search | ‚úÖ |
| Shopping Cart | Session + Persistent | ‚úÖ |
| Order Management | State machine | ‚úÖ |
| User Auth | JWT | ‚úÖ |
| Payments | Credit card + Konbini | ‚úÖ |
| Point System | Earn + Redeem | ‚úÖ |
| Inventory | Rust high-perf | ‚úÖ |
| Delivery | Basic slots | ‚úÖ |

### Infrastructure

| Component | Target | Status |
|-----------|--------|--------|
| Kubernetes | Production-ready | ‚úÖ |
| AWS | Terraform IaC | ‚úÖ |
| CI/CD | Automated | ‚úÖ |
| Monitoring | Grafana dashboards | ‚úÖ |

### Portfolio Value

- ‚úÖ Demonstrates **System Architecture** skills
- ‚úÖ Shows **Polyglot** development (Go, Rust, Python)
- ‚úÖ Proves **DevOps** expertise (Kubernetes, CI/CD, AWS)
- ‚úÖ Exhibits **Japan-Specific** domain knowledge
- ‚úÖ Shows **Production-Ready** practices

---

## üìä RISK MITIGATION

| Risk | Impact | Probability | Mitigation |
|------|--------|--------------|------------|
| Timeline overruns | High | Medium | MVP approach, focus on core features |
| Integration complexity | High | Medium | Incremental integration, testing |
| Performance bottlenecks | High | Low | Early performance testing, optimization |
| Cloud costs | Medium | Medium | Cost monitoring, optimization |
| Japan-specific complexity | Medium | Low | Research, partnerships |

---

## üöÄ DEPLOYMENT CHECKLIST

### Pre-Deployment
- [ ] All tests passing
- [ ] Security scans clean
- [ ] Documentation complete
- [ ] Backup strategy in place
- [ ] Monitoring configured
- [ ] Alerting rules set up

### Deployment
- [ ] Infrastructure provisioned (Terraform)
- [ ] Kubernetes cluster ready (EKS)
- [ ] Services deployed (kubectl)
- [ ] ConfigMaps/Secrets applied
- [ ] Ingress configured (ALB)

### Post-Deployment
- [ ] Health checks passing
- [ ] Monitoring data flowing
- [ ] Alerting configured
- [ ] Load test performed
- [ ] Documentation updated

---

## üìù PORTFOLIO DELIVERABLES

### Code Repository
- ‚úÖ Monorepo structure
- ‚úÖ 7 Go services
- ‚úÖ 1 Rust service
- ‚úÖ Complete protobuf definitions
- ‚úÖ Infrastructure code (Terraform, K8s)
- ‚úÖ CI/CD pipelines
- ‚úÖ Comprehensive tests
- ‚úÖ Documentation

### Documentation
- ‚úÖ Architecture overview
- ‚úÖ System design
- ‚úÖ API documentation
- ‚úÖ Deployment guide
- ‚úÖ Runbooks
- ‚úÖ Portfolio highlights

### Demo
- ‚úÖ Staging environment
- ‚úÖ Live API
- ‚úÖ Working e-commerce flow
- ‚úÖ Monitoring dashboards

---

## üéì LEARNING OUTCOMES

### Technical Skills Acquired

1. **Microservices Architecture**
   - Service boundaries (DDD)
   - Inter-service communication (gRPC)
   - Event-driven architecture (Kafka)

2. **Cloud-Native Development**
   - Kubernetes orchestration
   - AWS services integration
   - Infrastructure as Code (Terraform)

3. **Polyglot Programming**
   - Go (concurrency, gRPC)
   - Rust (performance, memory safety)
   - Python (analytics, scripting)

4. **Observability**
   - Metrics (Prometheus)
   - Tracing (Jaeger)
   - Logging (structured JSON)

5. **Japan-Specific Domain**
   - Konbini payment integration
   - Point system design
   - E-commerce patterns in Japan

### Professional Skills Demonstrated

- ‚úÖ **System Design**: Complex distributed systems
- ‚úÖ **DevOps**: CI/CD, automation
- ‚úÖ **Leadership**: Architecture decisions
- ‚úÖ **Communication**: Documentation
- ‚úÖ **Problem Solving**: Performance optimization

---

## üìö REFERENCE MATERIALS

### Books Read
- "Designing Data-Intensive Applications" by Martin Kleppmann
- "Building Microservices" by Sam Newman
- "Site Reliability Engineering" by Google SRE team
- "The Phoenix Project" by Gene Kim

### Technologies Mastered
- Go (concurrency, gRPC, sqlc)
- Rust (ownership, borrowing, async)
- PostgreSQL (advanced queries, indexing)
- Redis (caching strategies)
- Kubernetes (pods, services, ingress)
- AWS (EC2, EKS, RDS, S3, ELB)
- Prometheus/Grafana (metrics, dashboards)
- Jaeger (distributed tracing)

### Japanese E-commerce Knowledge
- Konbini payment providers (GMO, SB Payment)
- Point systems (Rakuten, PayPay)
- E-commerce regulations in Japan
- User experience expectations

---

## üéâ CONCLUSION

This comprehensive plan outlines a 20-24 week journey to build a production-grade, Japan-focused e-commerce platform.

### Key Highlights

- **20-24 Weeks**: Compressed timeline focused on MVP
- **Core E-commerce**: Products, Orders, Payments, Users
- **Japan-Specific**: Konbini payments, Point systems
- **AWS-First**: Cloud-agnostic Terraform modules
- **Breadth-First**: All services implemented (simplified for MVP)
- **Architecture Focus**: Demonstrates system design skills

### Portfolio Value

This project demonstrates to Japanese employers:
- ‚úÖ Senior backend engineering skills
- ‚úÖ Microservices architecture expertise
- ‚úÖ Cloud-native development experience
- ‚úÖ Japan-specific e-commerce knowledge
- ‚úÖ Production-ready practices
- ‚úÖ Polyglot programming capabilities

### Next Steps

1. **Review Plan**: Ensure all requirements are captured
2. **Phase 2-6**: Follow the implementation roadmap
3. **Iterate**: Adjust based on feedback and learning
4. **Portfolio**: Prepare for job applications

---

**Document Version**: 2.0
**Last Updated**: January 2026
**Author**: [Your Name]
**Contact**: [Your Email]
**GitHub**: https://github.com/yourusername/shinkansen-commerce
